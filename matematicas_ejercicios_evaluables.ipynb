{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObpOWDyPhIeBKt6ohYqdEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MareMaltese/matematicasAI/blob/main/matematicas_ejercicios_evaluables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Ejercicios evaluables\n",
        "\n",
        "## Tal y como ya hemos visto en clase, la variedad de herramientas proporcionadas por el algebra lineal son cruciales para desarrollar y fundamentar las bases de una variedad de tecnicas relacionadas con el aprendizaje autom√°tico. Con ella, podemos describir el proceso de propagacion hacia adelante en una red neuronal, identificar m√≠nimos locales en funciones multivariables (crucial para el proceso de retropropagaci√≥n) o la descripci√≥n y empleo de metodos de reducci√≥n de la dimensionalidad, como el an√°lisis de componentes principales(PCA), entre muchas otras aplicaciones.\n",
        "   \n",
        "Cuando trabajamos en la pr√°ctica dentro de este √°mbito, la cantidad de datos que manejamos puede ser muy grande, por lo que es especialmente importante emplear algoritmos eficientes y optimizados para reducir el coste computacional en la medida de lo posible. Por todo ello, el objetivo de este ejercicio es el de ilustrar las diferentes alternativas que pueden existir para realizar un proceso relacionado con el √°lgebra lineal y el impacto que puede tener cada variante en t√©rminos del coste computacional del mismo. En este caso en particular, y a modo de ilustraci√≥n, nos centraremos en el c√°lculo del determinante de una matriz."
      ],
      "metadata": {
        "id": "gRhjbmfnKPDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. [1 punto] Implementa una funci√≥n, determinante recursivo, que obtenga el determinante de una matriz cuadrada utilizando la definici√≥n recursiva de Laplace."
      ],
      "metadata": {
        "id": "rm1QG4V0KRet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3o7wu9hJoAl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def determinante_recursivo_pandas(matrix_df):\n",
        "    \"\"\"\n",
        "    Calcula el determinante de una matriz cuadrada utilizando la definici√≥n recursiva de Laplace.\n",
        "    Usa pandas para optimizar la manipulaci√≥n de submatrices.\n",
        "    Args:\n",
        "        matrix_df (pd.DataFrame): Matriz cuadrada como DataFrame\n",
        "    Returns:\n",
        "        float: Determinante de la matriz\n",
        "    \"\"\"\n",
        "    # Verificar si la matriz es cuadrada\n",
        "    if matrix_df.shape[0] != matrix_df.shape[1]:\n",
        "        raise ValueError(\"La matriz debe ser cuadrada\")\n",
        "\n",
        "    n = matrix_df.shape[0]\n",
        "\n",
        "    # Caso base: matriz 1x1\n",
        "    if n == 1:\n",
        "        return matrix_df.iloc[0, 0]\n",
        "\n",
        "    # Caso base: matriz 2x2\n",
        "    if n == 2:\n",
        "        return matrix_df.iloc[0, 0] * matrix_df.iloc[1, 1] - matrix_df.iloc[0, 1] * matrix_df.iloc[1, 0]\n",
        "\n",
        "    # Caso general: desarrollo por la primera fila (Laplace)\n",
        "    det = 0\n",
        "    for col in range(n):\n",
        "        # Crear submatriz eliminando la primera fila y la columna actual\n",
        "        submatrix = matrix_df.drop(index=matrix_df.index[0], columns=matrix_df.columns[col])\n",
        "\n",
        "        # Sumar al determinante con el signo alternante\n",
        "        det += ((-1) ** col) * matrix_df.iloc[0, col] * determinante_recursivo_pandas(submatrix)\n",
        "\n",
        "    return det\n",
        "\n",
        "# Ejemplo de uso\n",
        "data = [\n",
        "    [2, 1, 3],\n",
        "    [1, 0, 2],\n",
        "    [4, 1, 1]\n",
        "]\n",
        "\n",
        "# Crear un DataFrame de Pandas\n",
        "matrix_df = pd.DataFrame(data)\n",
        "print(\"Matriz:\")\n",
        "print(matrix_df)\n",
        "\n",
        "# Calcular el determinante\n",
        "det = determinante_recursivo_pandas(matrix_df)\n",
        "print(f\"Determinante (definici√≥n recursiva de Laplace usando Pandas): {det}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. [0.5 puntos] Si A es una matriz cuadrada n√ón y triangular (superior o inferior, es decir, con entradas nulas por debajo o por encima de la diagonal, respectivamente), ¬øexiste alguna forma de calcular de forma directa y sencilla su determinante? Justif√≠quese la respuesta"
      ],
      "metadata": {
        "id": "glVfVQERLasW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si. Para todas las matrices cuadradas triangulares (es decir, todos los n√∫meros por encima o por debajo de la diagonal son ceros), su determinante se puede calcular sencillamente multiplicando los n√∫meros de la diagonal principal.\n",
        "\n",
        "Debido a la **Propiedad Fundamental**:\n",
        "\n",
        "$$\n",
        "A = \\begin{bmatrix}\n",
        "a_{11} & a_{12} & a_{13} \\\\\n",
        "a_{21} & a_{22} & a_{23} \\\\\n",
        "a_{31} & a_{32} & a_{33}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\det(A) = a_{11} \\cdot a_{22} \\cdots a_{nn} = \\prod_{i=1}^n a_{ii}\n",
        "$$\n",
        "\n",
        "\n",
        "Si A es una matriz cuadrada n*n y triangular (superior o inferior), su determinante es igual al producto de los elementos en su diagonal principal.\n",
        "\n",
        "Por ejemplo, si la matriz es:\n",
        "$$\n",
        "A = \\begin{bmatrix}\n",
        "2 & 23 & 13 \\\\\n",
        "0 & 4 & 5 \\\\\n",
        "0 & 0 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Su determinante ser√° simplemente:\n",
        "2 ‚ãÖ 4 ‚ãÖ 6 = 48"
      ],
      "metadata": {
        "id": "uUalkA5bL2x6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. [0.5 puntos] Determ√≠nese de forma justificada c√≥mo alteran el determinante de una matriz n √ó n las dos operaciones elementales siguientes:"
      ],
      "metadata": {
        "id": "RD-RwtXXKfCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ### Intercambiar una fila (o columna) por otra fila (o columna).\n",
        "\n",
        "Si intercambiamos **dos filas** (o **dos columnas**) de una matriz cuadrada $( n \\times n $), el **determinante cambia de signo**.\n",
        "\n",
        "**Regla general:**\n",
        "Si $( A $) es la matriz original y $( B $) es la matriz despu√©s de intercambiar dos filas o columnas, entonces:\n",
        "\n",
        "$$\n",
        "\\det(B) = -\\det(A)\n",
        "$$\n",
        "\n",
        "El determinante de una matriz est√° relacionado con el **volumen orientado** definido por las filas o columnas de la matriz. **Intercambiar filas o columnas** no cambia el tama√±o del volumen, pero s√≠ su **orientaci√≥n** que se refleja como un **cambio de signo** en el determinante.\n",
        "\n",
        "---\n",
        "\n",
        "**Ejemplo:**\n",
        "\n",
        "Supongamos que tenemos la matriz:\n",
        "\n",
        "$$ A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "1 - Calculamos su determinante:\n",
        "$$ \\det(A) = 1 \\cdot 4 - 2 \\cdot 3 = -2 $$\n",
        "\n",
        "2 - Si intercambiamos las dos filas, obtenemos la matriz:\n",
        "$$\n",
        "B = \\begin{bmatrix}\n",
        "3 & 4 \\\\\n",
        "1 & 2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Ahora el determinante de (B) es:\n",
        "$$\n",
        "\\det(B) = 3 \\cdot 2 - 4 \\cdot 1 = 2\n",
        "$$\n",
        "\n",
        "Observamos que:\n",
        "$$\n",
        "\\det(B) = -\\det(A)\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b30r_38QXaT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ### Sumar a una fila (o columna) otra fila (o columna) multiplicada por un escalar Œ±\n",
        "\n",
        "Si sumamos a una fila (o columna) de una matriz otra fila (o columna) multiplicada por un **escalar** $\\alpha$ , el **determinante no cambia**.\n",
        "\n",
        "#### **Regla general:**\n",
        "Esta operaci√≥n **no altera el determinante** de la matriz. Es decir, si partimos de una matriz (A) y realizamos esta operaci√≥n, el determinante sigue siendo el mismo:\n",
        "$$\\det(B) = \\det(A)$$\n",
        "\n",
        "donde (B) es la matriz despu√©s de aplicar la operaci√≥n.\n",
        "\n",
        "\n",
        "El determinante mide el **volumen orientado** definido por las filas o columnas de la matriz.  \n",
        "Cuando sumamos a una fila otra fila multiplicada por un escalar, la fila original se \"desplaza\" en el espacio, sin cambiar el volumen.\n",
        "\n",
        "---\n",
        "\n",
        "**Ejemplo:**\n",
        "\n",
        "Supongamos que tenemos la matriz:\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "1 - Calculamos su determinante:\n",
        "$$\n",
        "\\det(A) = 1 \\cdot 4 - 2 \\cdot 3 = -2\n",
        "$$\n",
        "\n",
        "2 - Ahora sumamos a la **primera fila** la **segunda fila multiplicada por ( $\\alpha$ = 2 )**:\n",
        "$$\n",
        "B =\n",
        "\\begin{bmatrix}\n",
        "1 + 2 \\cdot 3 & 2 + 2 \\cdot 4 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "7 & 10 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "3 - Calculamos el determinante de (B):\n",
        "$$\n",
        "\\det(B) = 7 \\cdot 4 - 10 \\cdot 3 = -2\n",
        "$$\n",
        "\n",
        "Comprobado:\n",
        "$$\n",
        "\\det(B) = \\det(A)\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "4xanjyrJZmYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d ) [1 punto] Investiga sobre el m√©todo de eliminaci√≥n de Gauss con pivoteo parcial e\n",
        "implem√©ntalo para escalonar una matriz (es decir, convertirla en una matriz triangular\n",
        "inferior) a partir de las operaciones elementales descritas en el apartado anterior."
      ],
      "metadata": {
        "id": "q2dwWbFVSVwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**M√©todo de Eliminaci√≥n de Gauss con Pivoteo Parcial**\n",
        "\n",
        "La **eliminaci√≥n de Gauss con pivoteo parcial** es una t√©cnica utilizada para convertir una matriz $( A $) en una **matriz triangular inferior** (o escalonada) mediante **operaciones elementales**. Es una mejora del m√©todo de eliminaci√≥n de Gauss b√°sico, ya que mejora la **estabilidad num√©rica**.\n",
        "\n",
        "---\n",
        "\n",
        "### **¬øQu√© es el pivoteo parcial?**\n",
        "\n",
        "El **pivoteo parcial** consiste en seleccionar, en cada paso, el elemento de mayor valor absoluto de la columna actual (el pivote) y **reorganizar las filas** de la matriz para que dicho elemento quede en la posici√≥n diagonal actual.\n",
        "\n",
        "### **Operaciones Elementales Utilizadas**\n",
        "\n",
        "Durante el proceso, aplicamos las siguientes operaciones elementales:\n",
        "\n",
        "1. **Intercambiar filas**: Para asegurar que el pivote sea el mayor valor absoluto.\n",
        "   $[\n",
        "   F_i \\leftrightarrow F_j\n",
        "   ]$\n",
        "\n",
        "2. **Multiplicar una fila por un escalar**: Si una fila $( F_i $) se multiplica por un escalar $( $\\alpha$ $), se tiene:\n",
        "   $[\n",
        "   F_i \\to \\alpha F_i\n",
        "   $]\n",
        "\n",
        "3. **Sumar a una fila otra fila multiplicada por un escalar**: Para eliminar los elementos debajo del pivote:\n",
        "   $[\n",
        "   F_j \\to F_j - \\alpha F_i\n",
        "   $]\n",
        "   donde $( $\\alpha$ $) es el cociente entre el elemento de la fila actual y el pivote.\n",
        "\n",
        "---\n",
        "\n",
        "### **Pasos del M√©todo**\n",
        "\n",
        "1. Para cada columna $( k $) de la matriz:\n",
        "   - **Buscar el pivote**: Encontrar el elemento de mayor valor absoluto en la columna $( k $) a partir de la fila $( k $).\n",
        "   - **Intercambiar filas** si el pivote no est√° en la posici√≥n diagonal actual.\n",
        "2. Usar operaciones elementales para **eliminar los elementos debajo del pivote** y formar ceros en la columna $( k $).\n",
        "3. Repetir este proceso para todas las columnas.\n",
        "\n",
        "Al final del proceso, la matriz quedar√° **triangular inferior**.\n",
        "\n",
        "---\n",
        " **Ejemplo**\n",
        "\n",
        "Supongamos que tenemos la matriz $( A $):\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "2 & -1 & 1 \\\\\n",
        "-1 & 3 & 2 \\\\\n",
        "1 & -2 & 4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Paso 1: Selecci√≥n del pivote en la primera columna:**\n",
        "- El mayor valor absoluto en la primera columna es $( 2 $), as√≠ que no es necesario intercambiar filas.\n",
        "\n",
        "**Paso 2: Eliminaci√≥n de elementos debajo del pivote:**\n",
        "\n",
        "- Para la fila $( F_2 $):  \n",
        "   $$\n",
        "   F_2 \\to F_2 - \\left( \\frac{-1}{2} \\right) F_1\n",
        "   $$\n",
        "\n",
        "- Para la fila $( F_3 $):  \n",
        "   $$\n",
        "   F_3 \\to F_3 - \\left( \\frac{1}{2} \\right) F_1\n",
        "   $$\n",
        "\n",
        "**Paso 3: Repetimos el proceso para las siguientes columnas.**\n",
        "\n",
        "Al final, la matriz se transforma en una **matriz triangular inferior**:\n",
        "$$\n",
        "A_{\\text{escalonada}} =\n",
        "\\begin{bmatrix}\n",
        "2 & -1 & 1 \\\\\n",
        "0 & 2.5 & 2.5 \\\\\n",
        "0 & 0 & 3\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "2rLwsd3Ab3hV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e) [0.5 puntos] ¬øC√≥mo se podr¬¥ƒ±a calcular el determinante de una matriz haciendo beneficio de la estrategia anterior y del efecto de aplicar las operaciones elementales pertinentes?\n",
        "Implementa una nueva funci√≥n, determinante gauss, que calcule el determinante de\n",
        "una matriz utilizando eliminaci√≥n gaussiana."
      ],
      "metadata": {
        "id": "mPaP_SDASVnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def determinante_gauss(A):\n",
        "    \"\"\"\n",
        "    Calcula el determinante de una matriz cuadrada utilizando eliminaci√≥n gaussiana.\n",
        "\n",
        "    Args:\n",
        "        A (ndarray): Matriz cuadrada (n x n)\n",
        "\n",
        "    Returns:\n",
        "        float: Determinante de la matriz\n",
        "    \"\"\"\n",
        "    A = A.astype(float)  # Convertimos la matriz a tipo float para evitar errores num√©ricos\n",
        "    n = A.shape[0]  # Dimensi√≥n de la matriz\n",
        "    det = 1  # Inicializamos el determinante\n",
        "\n",
        "    for k in range(n):  # Recorremos las columnas\n",
        "        # Pivoteo parcial: encontramos el mayor valor absoluto en la columna k\n",
        "        max_row = np.argmax(np.abs(A[k:, k])) + k\n",
        "\n",
        "        # Si el pivote es cero, el determinante es cero\n",
        "        if np.isclose(A[max_row, k], 0):\n",
        "            return 0\n",
        "\n",
        "        # Intercambiamos filas si es necesario\n",
        "        if max_row != k:\n",
        "            A[[k, max_row]] = A[[max_row, k]]  # Intercambiar filas\n",
        "            det *= -1  # Cambiamos el signo del determinante\n",
        "\n",
        "        # Escalonado: eliminamos los elementos debajo del pivote\n",
        "        for i in range(k+1, n):\n",
        "            factor = A[i, k] / A[k, k]\n",
        "            A[i, k:] -= factor * A[k, k:]\n",
        "\n",
        "    # El determinante es el producto de la diagonal principal\n",
        "    det *= np.prod(np.diag(A))\n",
        "    return det\n",
        "\n",
        "# Ejemplo de uso\n",
        "A = np.array([[2, -1, 1],\n",
        "              [-1, 3, 2],\n",
        "              [1, -2, 4]])\n",
        "\n",
        "print(\"Matriz original:\")\n",
        "print(A)\n",
        "\n",
        "det = determinante_gauss(A)\n",
        "print(f\"Determinante calculado con eliminaci√≥n gaussiana: {det}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syMHtUsrePzv",
        "outputId": "283ea54f-e43a-4f52-b29a-6f39fe4a3546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz original:\n",
            "[[ 2 -1  1]\n",
            " [-1  3  2]\n",
            " [ 1 -2  4]]\n",
            "Determinante calculado con eliminaci√≥n gaussiana: 25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n del C√≥digo\n",
        "- Pivoteo Parcial:\n",
        "Se busca el mayor valor absoluto en la columna actual para usarlo como pivote. Si es necesario, se intercambian filas y se ajusta el signo del determinante.\n",
        "\n",
        "- Eliminaci√≥n de Elementos:\n",
        "Se eliminan los elementos debajo del pivote utilizando operaciones elementales.\n",
        "\n",
        "- Producto de la Diagonal:\n",
        "Al final del proceso, el determinante se obtiene como el producto de los elementos de la diagonal principal, ajustado seg√∫n el n√∫mero de intercambios de filas.\n",
        "\n",
        "- Eficiencia:\n",
        "Este m√©todo tiene una complejidad de\n",
        "$ùëÇ(ùëõ^3)$, lo que lo hace mucho m√°s eficiente que el c√°lculo recursivo de Laplace."
      ],
      "metadata": {
        "id": "a3K4FQeFeLRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### f ) [0.5 puntos] Obt√©n la complejidad computacional asociada al c√°lculo del determinante con la definici√≥n recursiva y con el m√©todo de eliminaci√≥n de Gauss con pivoteo parcial."
      ],
      "metadata": {
        "id": "jmUbWiWdUOhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Complejidad computacional del c√°lculo del determinante**\n",
        "\n",
        "El c√°lculo del determinante puede realizarse mediante diferentes m√©todos, pero la **eficiencia** depende del enfoque utilizado. A continuaci√≥n, se comparan las **complejidades computacionales** de:\n",
        "\n",
        "1. **La definici√≥n recursiva de Laplace**.\n",
        "2. **El m√©todo de eliminaci√≥n de Gauss con pivoteo parcial**.\n",
        "\n",
        "### **1. Definici√≥n recursiva de Laplace**\n",
        "\n",
        "La definici√≥n recursiva de Laplace expande el determinante desarrollando la matriz por una fila o columna. Para una matriz $( n \\times n $), este m√©todo requiere calcular $( n $) determinantes de submatrices de tama√±o $( (n-1) \\times (n-1) $).\n",
        "\n",
        "**Complejidad del m√©todo:**\n",
        "\n",
        "La expansi√≥n de Laplace es un proceso **recursivo**, donde en cada nivel de la recursi√≥n calculamos $( n $) determinantes de submatrices m√°s peque√±as. La complejidad se puede expresar como:\n",
        "\n",
        "$$\n",
        "T(n) = n \\cdot T(n-1)\n",
        "$$\n",
        "\n",
        "Resolviendo esta recurrencia, la complejidad es **factorial**:\n",
        "\n",
        "$$\n",
        "T(n) = O(n!)\n",
        "$$\n",
        "\n",
        "---\n",
        "**Ejemplo:**\n",
        "- Para $( n = 5 $): el c√°lculo requiere $( 120 $) operaciones.\n",
        "- Para $( n = 10 $): el n√∫mero de operaciones se vuelve inmanejable en la pr√°ctica.\n",
        "\n",
        "Por esta raz√≥n, el m√©todo de **Laplace** es **muy ineficiente** para matrices grandes y se utiliza principalmente con fines te√≥ricos o para matrices peque√±as.\n",
        "\n",
        "\n",
        "### **2. M√©todo de eliminaci√≥n de Gauss con pivoteo parcial**\n",
        "\n",
        "El m√©todo de eliminaci√≥n de Gauss transforma la matriz en una **matriz triangular superior** mediante **operaciones elementales**. El determinante se obtiene como el **producto de los elementos de la diagonal principal**.\n",
        "\n",
        "#### **Pasos clave:**\n",
        "1. Eliminar los elementos debajo de la diagonal utilizando operaciones elementales.\n",
        "2. El pivoteo parcial garantiza estabilidad num√©rica.\n",
        "\n",
        "\n",
        "**Complejidad del m√©todo:**\n",
        "La eliminaci√≥n de Gauss con pivoteo parcial realiza operaciones en cada fila y columna de la matriz. Para una matriz $( n \\times n $), el n√∫mero de operaciones es aproximadamente:\n",
        "\n",
        "$$\n",
        "T(n) = \\frac{n^3}{3} + O(n^2)\n",
        "$$\n",
        "\n",
        "Por lo tanto, la **complejidad asint√≥tica** es:\n",
        "\n",
        "$$\n",
        "T(n) = O(n^3)\n",
        "$$\n",
        "\n",
        "**Comparaci√≥n de complejidades**\n",
        "\n",
        "| **M√©todo**                         | **Complejidad** |\n",
        "|-----------------------------------|-----------------|\n",
        "| Definici√≥n recursiva de Laplace    | $( O(n!) $)     |\n",
        "| Eliminaci√≥n de Gauss (pivoteo parcial) | $( O(n^3) $)    |\n"
      ],
      "metadata": {
        "id": "tLBtHMT7e8xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### g ) [1 punto] Utilizando numpy.random.rand, genera matrices cuadradas aleatorias de la forma $An ‚ààRn \\times n$, para 2 ‚â§ n ‚â§ 10, y confecciona una tabla comparativa del tiempo de ejecuci√≥n asociado a cada una de las variantes siguientes, interpretando los resultados:\n",
        "- Utilizando determinante recursivo.\n",
        "- Empleando determinante gauss.\n",
        "- Haciendo uso de la funci√≥n preprogramada numpy.linalg.det.\n"
      ],
      "metadata": {
        "id": "O7IURp2kUO4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Determinante Recursivo\n",
        "def determinante_recursivo(matrix):\n",
        "    n = matrix.shape[0]\n",
        "    if n == 1:\n",
        "        return matrix[0, 0]\n",
        "    if n == 2:\n",
        "        return matrix[0, 0] * matrix[1, 1] - matrix[0, 1] * matrix[1, 0]\n",
        "\n",
        "    det = 0\n",
        "    for col in range(n):\n",
        "        submatrix = np.delete(np.delete(matrix, 0, axis=0), col, axis=1)\n",
        "        det += ((-1) ** col) * matrix[0, col] * determinante_recursivo(submatrix)\n",
        "    return det\n",
        "\n",
        "# 2. Determinante Gaussiano\n",
        "def determinante_gauss(matrix):\n",
        "    matrix = matrix.astype(float)\n",
        "    n = matrix.shape[0]\n",
        "    det = 1\n",
        "    for k in range(n):\n",
        "        max_row = np.argmax(np.abs(matrix[k:, k])) + k\n",
        "        if np.isclose(matrix[max_row, k], 0):\n",
        "            return 0\n",
        "        if max_row != k:\n",
        "            matrix[[k, max_row]] = matrix[[max_row, k]]\n",
        "            det *= -1\n",
        "        for i in range(k + 1, n):\n",
        "            factor = matrix[i, k] / matrix[k, k]\n",
        "            matrix[i, k:] -= factor * matrix[k, k:]\n",
        "    det *= np.prod(np.diag(matrix))\n",
        "    return det\n",
        "\n",
        "# 3. Comparaci√≥n de tiempos\n",
        "sizes = range(2, 11)  # Matrices de tama√±o 2x2 hasta 10x10\n",
        "results = []\n",
        "\n",
        "for n in sizes:\n",
        "    matrix = np.random.rand(n, n)  # Generar una matriz aleatoria\n",
        "    print(f\"Calculando determinantes para matriz {n}x{n}...\")\n",
        "\n",
        "    # M√©todo Recursivo\n",
        "    start = time.time()\n",
        "    det_rec = determinante_recursivo(matrix)\n",
        "    time_rec = time.time() - start\n",
        "\n",
        "    # M√©todo de Eliminaci√≥n Gaussiana\n",
        "    start = time.time()\n",
        "    det_gauss = determinante_gauss(matrix)\n",
        "    time_gauss = time.time() - start\n",
        "\n",
        "    # M√©todo Preprogramado\n",
        "    start = time.time()\n",
        "    det_np = np.linalg.det(matrix)\n",
        "    time_np = time.time() - start\n",
        "\n",
        "    # Guardar resultados\n",
        "    results.append({\n",
        "        \"Tama√±o\": n,\n",
        "        \"Tiempo Recursivo (s)\": time_rec,\n",
        "        \"Tiempo Gauss (s)\": time_gauss,\n",
        "        \"Tiempo Numpy (s)\": time_np\n",
        "    })\n",
        "\n",
        "# Crear una tabla con Pandas\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nTabla Comparativa de Tiempos:\")\n",
        "print(df_results)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df_results[\"Tama√±o\"], df_results[\"Tiempo Recursivo (s)\"], label=\"Recursivo\")\n",
        "plt.plot(df_results[\"Tama√±o\"], df_results[\"Tiempo Gauss (s)\"], label=\"Gauss\")\n",
        "plt.plot(df_results[\"Tama√±o\"], df_results[\"Tiempo Numpy (s)\"], label=\"Numpy\")\n",
        "plt.xlabel(\"Tama√±o de la Matriz (n)\")\n",
        "plt.ylabel(\"Tiempo de Ejecuci√≥n (s)\")\n",
        "plt.title(\"Comparaci√≥n de M√©todos para C√°lculo del Determinante\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "nAE4cHiVhMEY",
        "outputId": "9fb85fe6-9e45-46d8-d129-b31b49f3396e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando determinantes para matriz 2x2...\n",
            "Calculando determinantes para matriz 3x3...\n",
            "Calculando determinantes para matriz 4x4...\n",
            "Calculando determinantes para matriz 5x5...\n",
            "Calculando determinantes para matriz 6x6...\n",
            "Calculando determinantes para matriz 7x7...\n",
            "Calculando determinantes para matriz 8x8...\n",
            "Calculando determinantes para matriz 9x9...\n",
            "Calculando determinantes para matriz 10x10...\n",
            "\n",
            "Tabla Comparativa de Tiempos:\n",
            "   Tama√±o  Tiempo Recursivo (s)  Tiempo Gauss (s)  Tiempo Numpy (s)\n",
            "0       2              0.000023          0.000430          0.000055\n",
            "1       3              0.000141          0.000378          0.000045\n",
            "2       4              0.002197          0.000399          0.000028\n",
            "3       5              0.002750          0.000489          0.000029\n",
            "4       6              0.006099          0.000515          0.000050\n",
            "5       7              0.040076          0.000660          0.000044\n",
            "6       8              0.351766          0.000785          0.000042\n",
            "7       9              3.062117          0.000848          0.000043\n",
            "8      10             34.490778          0.001048          0.000050\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHHCAYAAABKudlQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5tklEQVR4nO3dd3hT1R8G8DdN03S3QDctLbSFtoyysSBD9iqgKLJbQRSFnwxBxMGWpTJkFFAsCFYUBERkFWTIHlo2CIUCAmV30zZNzu+PmkjoIElT0qTv53mq5Nybc7/npkm+PfeccyVCCAEiIiIiM2Vl6gCIiIiISoLJDBEREZk1JjNERERk1pjMEBERkVljMkNERERmjckMERERmTUmM0RERGTWmMwQERGRWWMyQ2XOt99+i6VLl5o6DJM7deoUJk2ahBs3bpg6FCohIQTmzJmDn376ydShEFkkJjP0XLVq1QqtWrUqcvvatWsxYsQINGrU6LnEs2LFCkgkEiQlJT2X4+kqNTUVL7/8Mh49egQ/P7/ncsykpCRIJBKsWLHiuRyvPJk9eza++OILvPDCCwW2BQQEIDo6utSOHR0djYCAgFKrX+1Z7+3ilPY5MHd79uyBRCLBnj17TB1KmcVkRgeJiYl4++23Ua1aNdja2sLZ2RnNmjXD/Pnz8fjxY1OHZzEuXbqEoUOH4qeffkL9+vVNHY5B1B86EokEq1evLnSfZs2aQSKRoFatWkXW88Ybb6BevXqYO3dugW1xcXGYN2+esUImPSUkJKB///7w8/ODXC5HxYoV0bZtW8TGxkKpVBbY/9ChQ5g1axZ+++03VKlSxQQRWw71e0sikcDa2hoVK1ZEgwYNMGLECJw7d65EdU+fPh0bN240TqAWbsuWLZg0aZKpw9BibeoAyrrffvsNr732GuRyOQYOHIhatWohNzcX+/fvx9ixY3H27FksW7bM1GGajR07dhS57eTJk4iNjUWnTp2eY0Slw9bWFnFxcejfv79WeVJSEg4ePAhbW9sin5uUlISGDRti9OjRsLIq+PdGXFwczpw5g5EjRxo7bHqGb775BkOHDoWnpycGDBiA4OBgpKenY9euXRg8eDBu376Njz76SOs558+fx8aNG1GvXj0TRW1Z2rVrh4EDB0IIgdTUVJw8eRIrV67E4sWLMWvWLIwePdqgeqdPn45XX30VPXr0MG7ARtCiRQs8fvwYNjY2pg4FQH4ys2jRojKV0DCZKcbVq1fRu3dv+Pv74/fff4e3t7dm27Bhw3D58mX89ttvJoyw9KhUKuTm5hb7pWuI4t6Mr776qlGPZUqdO3fGpk2bcP/+fbi5uWnK4+Li4OnpieDgYDx69KjQ5wYEBBT4QiTDCSGQnZ0NOzu7EtVz+PBhDB06FBEREdiyZQucnJw020aOHInjx4/jzJkzBZ43aNCgEh2XtFWvXr3AHwkzZ85EZGQk3n//fYSEhKBz584mik5bdnY2bGxsCv2jRB9WVlZG/yy2NLzMVIzZs2cjIyMDy5cv10pk1IKCgjBixAjN47y8PEydOhWBgYGQy+WaL6WcnByt5wUEBKBr167Ys2cPGjZsCDs7O9SuXVtzPXT9+vWoXbs2bG1t0aBBA/z1119az4+OjoajoyOuXLmCDh06wMHBAT4+PpgyZQqevgn6F198gaZNm6JSpUqws7NDgwYNsG7dugJtkUgkGD58OL7//nvUrFkTcrkc27Zt06sOAFi9ejUaN24Me3t7VKhQAS1atNDqjSnsuvrdu3cxePBgeHp6wtbWFuHh4Vi5cqXWPurxHF988QWWLVumOceNGjXCsWPHCo3laWfPnkXr1q1hZ2cHX19fTJs2DSqVqtB9t27diubNm8PBwQFOTk7o0qULzp49q9NxAKB79+6Qy+VYu3atVnlcXBx69eoFqVRa6PNWr16NBg0awM7ODhUrVkTv3r21BgC3atUKv/32G65du6bpbn9yPIQu5xIAUlJSEB0dDRcXF7i6uiIqKgopKSmFxvT7779rzoWrqyu6d++O8+fPa+2Tnp6OkSNHIiAgAHK5HB4eHmjXrh3+/PPPYs/TpEmTIJFIcOHCBfTq1QvOzs6oVKkSRowYgezsbK19Y2Nj0bp1a3h4eEAulyMsLAwxMTEF6lS/v7Zv3655f6kHlOtaR2EmT54MiUSC77//XiuRUWvYsKHWuA993jdPS0lJwahRozTn09fXFwMHDsT9+/cBFD3WS9exFZmZmXj//fc1l8pq1KiBL774osDnR1HU70E7Ozs0btwYf/zxR6H75eTkYOLEiQgKCoJcLoefnx8++OCDAp+JJVWpUiWsWbMG1tbW+Oyzz/SOQSKRIDMzEytXrtS8r558LW/evIlBgwbB09MTcrkcNWvWxLfffqt1HPW5X7NmDT755BNUrlwZ9vb2SEtL03xmX79+HV27doWjoyMqV66MRYsWAQBOnz6N1q1bw8HBAf7+/oiLiyu07idf11atWqFWrVo4d+4cXnrpJdjb26Ny5cqYPXu21nNzc3MxYcIENGjQAC4uLnBwcEDz5s2xe/durf10/YyNjo7WxP3kZT81lUqFefPmoWbNmrC1tYWnpyfefvvtIv94MxpBRapcubKoVq2azvtHRUUJAOLVV18VixYtEgMHDhQARI8ePbT28/f3FzVq1BDe3t5i0qRJYu7cuaJy5crC0dFRrF69WlSpUkXMnDlTzJw5U7i4uIigoCChVCq1jmNrayuCg4PFgAEDxMKFC0XXrl0FAPHpp59qHcvX11e8++67YuHChWLOnDmicePGAoDYvHmz1n4ARGhoqHB3dxeTJ08WixYtEn/99ZdedUyaNEkAEE2bNhWff/65mD9/vujbt68YN26cZp+WLVuKli1bah5nZWWJ0NBQIZPJxKhRo8RXX30lmjdvLgCIefPmafa7evWqACDq1asngoKCxKxZs8Ts2bOFm5ub8PX1Fbm5ucW+Nrdv3xbu7u6iQoUKYtKkSeLzzz8XwcHBok6dOgKAuHr1qmbf7777TkgkEtGxY0exYMECMWvWLBEQECBcXV219ivM7t27BQCxdu1a0bdvX9G8eXPNtoSEBAFAHDp0SLRs2VLUrFlT67nTpk0TEolEvP7662Lx4sVi8uTJws3NTQQEBIhHjx4JIYTYsWOHqFu3rnBzcxOrVq0Sq1atEhs2bNDrXKpUKtGiRQthZWUl3n33XbFgwQLRunVrzbmIjY3V7BsfHy+sra1F9erVxezZszUxVahQQetc9O3bV9jY2IjRo0eLb775RsyaNUtERkaK1atXF3u+Jk6cKACI2rVri8jISLFw4ULRv39/AUAMGDBAa99GjRqJ6OhoMXfuXLFgwQLRvn17AUAsXLhQaz9/f38RFBQkKlSoID788EOxZMkSsXv3br3qeFpmZqaQyWSidevWxe73pMqVK4t33nlH875p2LBhoe8bf39/ERUVpXmcnp4uatWqJaRSqRgyZIiIiYkRU6dOFY0aNdK8J2NjYwv83grx3++fur1C5H9e+Pv7ax6rVCrRunVrIZFIxJtvvikWLlwoIiMjBQAxcuTIZ7brm2++0bzPv/rqKzFy5Ejh6uoqqlWrpvXeViqVon379sLe3l6MHDlSLF26VAwfPlxYW1uL7t27F3sOigJADBs2rMjtbdq0EVZWViI1NVWvGFatWiXkcrlo3ry55n118OBBIYQQycnJwtfXV/j5+YkpU6aImJgY0a1bNwFAzJ07V1OH+tyHhYWJunXrijlz5ogZM2aIzMxMzWd2WFiYGDp0qFi0aJFo2rSp5v3m4+Mjxo4dKxYsWCBq1qwppFKpuHLlSoG6n3xdW7ZsKXx8fISfn58YMWKEWLx4sWjdurUAILZs2aLZ7969e8Lb21uMHj1axMTEiNmzZ4saNWoImUym+X0SQvfP2IMHD4p27doJAJpztWrVKk09b775prC2thZDhgwRS5YsEePGjRMODg6iUaNGz/ycLgkmM0VITU0VAAq86Yqi/qJ68803tcrHjBkjAIjff/9dU+bv7y8AaN4sQgixfft2AUDY2dmJa9euacqXLl1a6IcTAPG///1PU6ZSqUSXLl2EjY2NuHfvnqY8KytLK57c3FxRq1atAh/KAISVlZU4e/ZsgbbpUselS5eElZWVePnll7USL3Vsak8nM/PmzRMAtL70cnNzRUREhHB0dBRpaWlCiP/eaJUqVRIPHz7U7PvLL78IAOLXX38tEPeTRo4cKQCII0eOaMru3r0rXFxctL4U0tPThaurqxgyZIjW85OTk4WLi0uB8qc9mcxs3rxZSCQScf36dSGEEGPHjtUkx08nM0lJSUIqlYrPPvtMq77Tp08La2trrfIuXbpofTmp6XouN27cKACI2bNna/bLy8vTJD5PJjN169YVHh4e4sGDB5qykydPCisrKzFw4EBNmYuLS7FfMkVRJzPdunXTKn/33XcFAHHy5ElN2dO/h0II0aFDhwJ/cKjfX9u2bSuwv651PO3kyZMCgBgxYkSx+z0pIyND63Fubq4ICwsr8N57+ot8woQJAoBYv359gTrV76WSJDPq13/atGlaz3311VeFRCIRly9fLrJNubm5wsPDQ9StW1fk5ORoypctWyYAaL23V61aJaysrMQff/yhVceSJUsEAHHgwIEiz0FRnpXMjBgxQuv3Rp8YHBwcCo1h8ODBwtvbW9y/f1+rvHfv3sLFxUXzO6U+99WqVSvwe6b+zJ4+fbqm7NGjR8LOzk5IJBKxZs0aTfmFCxcEADFx4kRNWVHJDADx3XffacpycnKEl5eX6Nmzp6YsLy9P67VSH9vT01MMGjRIU6bPZ+ywYcNEYX0hf/zxhwAgvv/+e63ybdu2FVpuTLzMVIS0tDQAKLQ7uTBbtmwBgAKDz95//30AKDC2JiwsDBEREZrHTZo0AQC0bt1aa8aDuvzKlSsFjjl8+HDNv9WXiXJzc7Fz505N+ZPjBB49eoTU1FQ0b9680O7/li1bIiwsrEC5LnVs3LgRKpUKEyZMKHB9+MkuyKdt2bIFXl5e6NOnj6ZMJpPhvffeQ0ZGBvbu3au1/+uvv44KFSpoHjdv3hxA4efn6eO88MILaNy4sabM3d0d/fr109ovPj4eKSkp6NOnD+7fv6/5kUqlaNKkSYGu2eK0b98eFStWxJo1ayCEwJo1a7Ta+aT169dDpVKhV69eWsf18vJCcHCwTsfV9Vxu2bIF1tbWeOeddzT7SaVS/O9//9Oq7/bt20hISEB0dDQqVqyoKa9Tpw7atWun+Z0HAFdXVxw5cgS3bt3S7eQ8ZdiwYVqP1bE8eYwnfw9TU1Nx//59tGzZEleuXEFqaqrW86tWrYoOHToUOI4+dTxJ388DAHBwcND8W6FQQKlUom3bts+89Pbzzz8jPDwcL7/8coFtxb2XdLVlyxZIpVK89957WuXvv/8+hBDYunVrkc89fvw47t69i6FDh2qNf1NfsnzS2rVrERoaipCQEK3f6datWwOAXu8lXTk6OgLIv+xpjBiEEPj5558RGRkJIYRWHR06dEBqamqB1zMqKqrI8Vlvvvmm5t+urq6oUaMGHBwc0KtXL015jRo14Orq+szPNHV7nxw/ZGNjg8aNG2s9VyqVal4rlUqFhw8fIi8vDw0bNiz0d9HQz1gg/3y7uLigXbt2WueqQYMGcHR0LJXXXI0DgIvg7OwM4L83xbNcu3YNVlZWCAoK0ir38vKCq6srrl27plX+9BRN9QfB02uKqMufvt5oZWWFatWqaZVVr14dALSuo2/evBnTpk1DQkJCgWvET6tatWqhbdOljsTERFhZWRWaDBXn2rVrCA4OLpAAhYaGarY/6enzpn7TPet67LVr1zSJ4ZNq1Kih9fjSpUsAoPmwe5r690IXMpkMr732GuLi4tC4cWPcuHEDffv2LXTfS5cuQQiB4ODgIut6Fl3P5bVr1+Dt7a354Fd7+lyo93+6XF3n9u3bkZmZCQcHB8yePRtRUVHw8/NDgwYN0LlzZwwcOLDA72hRnm53YGAgrKystH6XDxw4gIkTJ+LQoUPIysrS2j81NVXry7So32V96niSvp8HQH5iPHPmTCQkJODhw4ea8mclJImJiejZs6fOx9HXtWvX4OPjUyAxK+o99/RzgYKvl0wmK/BaX7p0CefPn4e7u3uhdd29e1fv2J8lIyMDwH9JZ0ljuHfvHlJSUrBs2bIiZ60+XUdRv3u2trYF4nBxcYGvr2+B3wkXFxedxpgU9twKFSrg1KlTWmUrV67El19+iQsXLkChUBQbq6GfsUD++U5NTYWHh0eh20vjNVdjMlMEZ2dn+Pj4FDo7oTi6/uVU1ADQosqFjgPznvTHH3+gW7duaNGiBRYvXgxvb2/IZDLExsYWGGAGoNC/JvSto7QZ8/wURj0geNWqVfDy8iqw3dpav7dM3759sWTJEkyaNAnh4eFFJnsqlQoSiQRbt24ttI1PJx5lTa9evdC8eXNs2LABO3bswOeff45Zs2Zh/fr1Bk21f/p9lJiYiDZt2iAkJARz5syBn58fbGxssGXLFsydO7fAQO7Cfpf1reNJQUFBsLa2xunTp3WK/+DBg+jYsSPatm2LxYsXw8fHBzKZDEuWLCl0QLa+ivqcKWydG1NRqVSoXbs25syZU+j20lgM8syZM5BKpZov6ZLGoP6d6N+/P6Kiogrdp06dOlqPi+qVKY3PfF2eu3r1akRHR6NHjx4YO3YsPDw8IJVKMWPGDCQmJho1HpVKBQ8PD3z//feFbi8qqTQGJjPF6Nq1K5YtW4ZDhw5pXRIqjL+/P1QqFS5duqT5CwcA7ty5g5SUFPj7+xs1NpVKhStXrmh6YwDg77//BgDN7Jaff/4Ztra22L59O+RyuWa/2NhYnY+jax2BgYFQqVQ4d+4c6tatq3P9/v7+OHXqFFQqlVaPwoULFzTbjcHf31/T6/Kkixcvaj0ODAwEAHh4eKBt27YlPu6LL76IKlWqYM+ePZg1a1aR+wUGBkIIgapVq2q9poUp6otM13Pp7++PXbt2ISMjQytJevpcqPd/ulxdp5ubm9alFG9vb7z77rt49913cffuXdSvXx+fffaZTsnMpUuXtP5KvHz5MlQqleZ3+ddff0VOTg42bdqk9ZejPt3WJanD3t4erVu3xu+//44bN24880tw7dq1sLW1xa+//qp1Oearr7565rECAwOf+UeU+q/lp2egFderoubv74+dO3ciPT1dq3dGl/ecetulS5e0ei8VCgWuXr2K8PBwrXacPHkSbdq0McrlsWe5fv069u7di4iICE279ImhsO3u7u5wcnLSXCI0R+vWrUO1atWwfv16rTZOnDjR4DqLOpeBgYHYuXMnmjVrVuKlEPTFMTPF+OCDD+Dg4IA333wTd+7cKbA9MTER8+fPBwDNugZPr8yq/ougS5cuRo9v4cKFmn8LIbBw4ULIZDK0adMGQH6GLZFItP5aS0pK0muVS13r6NGjB6ysrDBlypQCf+EWl9F37twZycnJ+PHHHzVleXl5WLBgARwdHdGyZUudYy1O586dcfjwYRw9elRTdu/evQJ/QXTo0AHOzs6YPn26Vnfsk8/Rh0QiwVdffYWJEydiwIABRe73yiuvQCqVYvLkyQXOlxACDx480Dx2cHAodHyHrueyc+fOyMvL05qSrFQqsWDBAq36vL29UbduXaxcuVLrS/PMmTPYsWOH5ndeqVQWiMfDwwM+Pj46T8FVT/VUU8eiToTUfy0+eW5SU1P1SsxLWsfEiRMhhMCAAQM0lzOedOLECU2vi/rDPi8vT7P9ypUrOr33evbsiZMnT2LDhg0FtqljVyfd+/bt02xTKpU6LeDZuXNnKJVKrc8PAJg7dy4kEkmxyWfDhg3h7u6OJUuWIDc3V1O+YsWKAolVr169cPPmTXz99dcF6nn8+DEyMzOfGauuHj58iD59+kCpVOLjjz82KAYHB4cCbZBKpejZsyd+/vnnQhNMfT8PTKGw3/sjR47g0KFDBtep/iOmsNdcqVRi6tSpBZ6Tl5dX5PIPxsCemWIEBgYiLi4Or7/+OkJDQ7VWAD548CDWrl2rWYsgPDwcUVFRWLZsGVJSUtCyZUscPXoUK1euRI8ePfDSSy8ZNTZbW1ts27YNUVFRaNKkCbZu3YrffvsNH330kaYrr0uXLpgzZw46duyIvn374u7du1i0aBGCgoIKXFMtiq51BAUF4eOPP8bUqVPRvHlzvPLKK5DL5Th27Bh8fHwwY8aMQut/6623sHTpUkRHR+PEiRMICAjAunXrcODAAcybN0+vAZfF+eCDD7Bq1Sp07NgRI0aMgIODA5YtW6bpzVBzdnZGTEwMBgwYgPr166N3795wd3fH9evX8dtvv6FZs2YFvgSepXv37ujevXux+wQGBmLatGkYP348kpKS0KNHDzg5OeHq1avYsGED3nrrLYwZMwYA0KBBA/z4448YPXo0GjVqBEdHR0RGRup8LiMjI9GsWTN8+OGHSEpKQlhYGNavX19ogvT555+jU6dOiIiIwODBg/H48WMsWLAALi4umtU/09PT4evri1dffRXh4eFwdHTEzp07cezYMXz55Zc6naOrV6+iW7du6NixIw4dOoTVq1ejb9++mr/027dvDxsbG0RGRuLtt99GRkYGvv76a3h4eOD27ds6HaOkdTRt2hSLFi3Cu+++i5CQEK0VgPfs2YNNmzZh2rRpAPIThrlz52q9bxYuXIgaNWogISGh2OOMHTsW69atw2uvvYZBgwahQYMGePjwITZt2oQlS5YgPDwcNWvWxAsvvIDx48fj4cOHmoHmTyZPRYmMjMRLL72Ejz/+GElJSQgPD8eOHTvwyy+/YOTIkZpEqTAymQzTpk3D22+/jdatW+P111/H1atXERsbW2DMzIABA/DTTz9h6NCh2L17N5o1awalUokLFy7gp59+0qwDpK+///4bq1evhhACaWlpOHnyJNauXYuMjAzNZ5UhMTRo0AA7d+7EnDlz4OPjg6pVq6JJkyaYOXMmdu/ejSZNmmDIkCEICwvDw4cP8eeff2Lnzp1a46HKoq5du2L9+vV4+eWX0aVLF1y9ehVLlixBWFhYoUm5Lho0aAAAeO+999ChQwdIpVL07t0bLVu2xNtvv40ZM2YgISEB7du3h0wmw6VLl7B27VrMnz+/9BZHLbV5Uhbk77//FkOGDBEBAQHCxsZGODk5iWbNmokFCxaI7OxszX4KhUJMnjxZVK1aVchkMuHn5yfGjx+vtY8Q+dMQu3TpUuA4KGTaoXq63Oeff64pi4qKEg4ODiIxMVGzhoKnp6eYOHFigWnRy5cvF8HBwUIul4uQkBARGxurmQ77rGPrW4cQQnz77beiXr16Qi6XiwoVKoiWLVuK+Ph4zfanp2YLIcSdO3fEG2+8Idzc3ISNjY2oXbu21vTgos7Dk7E/OY2xKKdOnRItW7YUtra2onLlymLq1Kli+fLlRU5x7dChg3BxcRG2trYiMDBQREdHi+PHjxd7jCenZhensHVmhBDi559/Fi+++KJwcHAQDg4OIiQkRAwbNkxcvHhRs09GRobo27evcHV1FQC0pt3qci6FEOLBgwdiwIABwtnZWbi4uIgBAwaIv/76q8DUbCGE2Llzp2jWrJmws7MTzs7OIjIyUpw7d06zPScnR4wdO1aEh4cLJycn4eDgIMLDw8XixYuLPQdC/Dc1+9y5c+LVV18VTk5OokKFCmL48OHi8ePHWvtu2rRJ1KlTR9ja2oqAgAAxa9Ys8e233xZ4/Yp6f+lTR3FOnDgh+vbtK3x8fIRMJhMVKlQQbdq0EStXrtR6/y1btkwEBQUJuVwuwsLCxHfffVfo+6awackPHjwQw4cPF5UrVxY2NjbC19dXREVFaU0PTkxMFG3bthVyuVx4enqKjz76SMTHxz9zarYQ+UsQjBo1StOG4OBg8fnnn2sto1CcxYsXi6pVqwq5XC4aNmwo9u3bV+h7Ozc3V8yaNUvUrFlT85nQoEEDMXnyZM1aMEWdg8IA0PxYWVkJV1dXUa9ePTFixIhCl5XQJ4YLFy6IFi1aCDs7OwFAK547d+6IYcOGCT8/PyGTyYSXl5do06aNWLZsmWaf4t776s/spxX1OfD073BRU7MLe25h6wpNnz5d+Pv7C7lcLurVqyc2b95cYD99PmPz8vLE//73P+Hu7i4kEkmB3+lly5aJBg0aCDs7O+Hk5CRq164tPvjgA3Hr1q0CdRuL5N9AyYxER0dj3bp1BmfVRGXFpEmTMHnyZNy7d0/rtg9ERPrgmBkiIiIya0xmiIiIyKwxmSEiIiKzxjEzREREZNbYM0NERERmjckMERERmTWLXzRPpVLh1q1bcHJyei5LahMREVHJCSGQnp4OHx+fAjfQfZrFJzO3bt0qlRuaERERUem7ceMGfH19i93H4pMZ9RLuN27cgLOzs1HrVigU2LFjh2bJZktj6e0DLL+NbJ/5s/Q2sn3mr7TamJaWBj8/P51ua2PxyYz60pKzs3OpJDP29vZwdna2yF9SS28fYPltZPvMn6W3ke0zf6XdRl2GiHAAMBEREZk1JjNERERk1pjMEBERkVmz+DEzulIqlVAoFHo9R6FQwNraGtnZ2VAqlaUUmemYY/tkMhmkUqmpwyAioueo3CczQggkJycjJSXFoOd6eXnhxo0bFrmGjbm2z9XVFV5eXmYVMxERGc6kyUxMTAxiYmKQlJQEAKhZsyYmTJiATp06AQBatWqFvXv3aj3n7bffxpIlS4wWgzqR8fDwgL29vV5fgCqVChkZGXB0dHzmgj7myNzaJ4RAVlYW7t69CwDw9vY2cURERPQ8mDSZ8fX1xcyZMxEcHAwhBFauXInu3bvjr7/+Qs2aNQEAQ4YMwZQpUzTPsbe3N9rxlUqlJpGpVKmS3s9XqVTIzc2Fra2tWXzZ68sc22dnZwcAuHv3Ljw8PHjJiYioHDBpMhMZGan1+LPPPkNMTAwOHz6sSWbs7e3h5eVVKsdXj5ExZoJEpqd+PRUKBZMZIqJyoMyMmVEqlVi7di0yMzMRERGhKf/++++xevVqeHl5ITIyEp9++mmxyUdOTg5ycnI0j9PS0gDkf7E9PcBXoVBACAEhBFQqld4xCyE0/zfk+WWdubZP/Zrqksyofyf0HfxtLtg+82fpbWT7zF9ptVGf+iRC/Y1lIqdPn0ZERASys7Ph6OiIuLg4dO7cGQCwbNky+Pv7w8fHB6dOncK4cePQuHFjrF+/vsj6Jk2ahMmTJxcoj4uLK5AEWVtbw8vLC35+frCxsTFuw8hkcnNzcePGDSQnJyMvL8/U4RARkQGysrLQt29fpKamPnMFf5MnM7m5ubh+/TpSU1Oxbt06fPPNN9i7dy/CwsIK7Pv777+jTZs2uHz5MgIDAwutr7CeGT8/P9y/f7/AycjOzsaNGzcQEBAAW1tbvWNX39HTUu/IXRrtk0ql+Pnnn9GjRw+j1FeY7OxsJCUlwc/P75mvq0KhQHx8PNq1a2eRS42zfebP0tvI9pm/0mpjWloa3NzcdEpmTH6ZycbGBkFBQQCABg0a4NixY5g/fz6WLl1aYN8mTZoAQLHJjFwuh1wuL1Auk8kKnGSlUgmJRAIrKyuDBriqL72o63ieoqOjsXLlSgD5PUy+vr547bXXMGXKFIMSs8KURvtu376NChUqlOr5srKygkQiKfQ1L4o++5ojts/8WXob2T7zZ+w26lOXyZOZp6lUKq2elSclJCQA4JRbtY4dOyI2NhYKhQInTpxAVFQUJBIJZs2aZZJ4cnNzn3m5rrQGcxMR0fMnhMDpm6nINfG6qiadbzt+/Hjs27cPSUlJOH36NMaPH489e/agX79+SExMxNSpU3HixAkkJSVh06ZNGDhwIFq0aIE6deqYMuwyQy6Xa8b89OjRA23btkV8fDyA/KRwxowZqFq1Kuzs7BAeHo5169ZpPf/s2bPo2rUrnJ2d4eTkhObNmyMxMRFA/ho/o0aN0tq/R48eiI6O1jwOCAjA1KlTMXDgQDg7O+Ott95Cbm4uhg8fDm9vb9ja2sLf3x8zZszQPEcikWDjxo0AgKZNm2LcuHFax7h37x5kMhn27dsHAHj06BEGDhyIChUqwN7eHp06dcKlS5eMcv6IiKhk/nn0GK8sOYKPjkuRpzTdRBGT9szcvXsXAwcOxO3bt+Hi4oI6depg+/btaNeuHW7cuIGdO3di3rx5yMzMhJ+fH3r27IlPPvmkVGMSQuCxQrcUU6VS4XGuEta5eUa5bGInkxo8NuXMmTM4ePAg/P39AQAzZszA6tWrsWTJEgQHB2Pfvn3o378/3N3d0bJlS9y8eRMtWrRAq1at8Pvvv8PZ2RkHDhzQe8DsF198gQkTJmDixIkAgK+++gqbNm3CTz/9hCpVquDGjRu4ceNGoc/t168fZs+ejZkzZ2ra/eOPP8LHxwfNmzcHkH857dKlS9i0aROcnZ0xbtw4dO7cGefOnbP4LlsiorLu3O38GcMetoC11HT9IyZNZpYvX17kNj8/vwKr/z4PjxVKhE3Y/tyPCwDnpnSAvY3uL8nmzZvh6OiIvLw85OTkwMrKCgsXLkROTg6mT5+OnTt3aqa5V6tWDfv378fSpUvRsmVLLFq0CC4uLlizZo0mKahevbreMbdu3Rrvv/++5vH169cRHByMF198ERKJRJNcFaZXr14YOXIk9u/fr0le4uLi0KdPH0gkEk0Sc+DAATRt2hRA/lR9Pz8/bNy4Ea+99pre8RIRkfGc/zeZqexg0rlEZW/MDOnupZdeQkxMDDIzMzF37lxYW1ujZ8+eOHv2LLKystCuXTut/XNzc1GvXj0A+eOPmjdvXuLejYYNG2o9jo6ORrt27VCjRg107NgRXbt2Rfv27Qt9rru7O9q3b4/vv/8ezZs3x9WrV3Ho0CHN4O/z58/D2tpaM/AbACpVqoQaNWrg/PnzJYqbiIhK7tyt/GTGx57JTJliJ5Pi3JQOOu2rUqmQnpYOJ2cno11m0oeDg4NmJti3336L8PBwLF++HLVq1QIA/Pbbb6hcubLWc9QzvdTL/hfFysoKT8/aL2wBIwcHB63H9evXx9WrV7F161bs3LkTvXr1Qtu2bQuM11Hr168f3nvvPSxYsABxcXGoXbs2ateuXWxsRERUNpxPVvfMmDYOJjNPkUgkOl/qUalUyLORwt7G2uT3LrKyssJHH32E0aNH4++//4ZcLsf169fRsmXLQvevU6cOVq5cCYVCUWjvjLu7O27fvq15rFQqcebMGbz00kvPjMXZ2Rmvv/46Xn/9dbz66qvo2LEjHj58iIoVKxbYt3v37njrrbewbds2xMXFYeDAgZptoaGhyMvLw5EjRzSXmR48eICLFy8Wug4RERE9P+nZCtx4+BgAUNnEPTPmcfdA0slrr70GqVSKpUuXYsyYMRg1ahRWrlyJxMRE/Pnnn1iwYIFmbZrhw4cjLS0NvXv3xvHjx3Hp0iWsWrUKFy9eBJA/FmbLli3Yvn07Lly4gHfeeQcpKSnPjGHOnDn44YcfcOHCBfz9999Yu3YtvLy84OrqWuj+Dg4O6NGjBz799FOcP38effr00WwLDg5G9+7dMWTIEOzfvx8nT55E//79UblyZXTv3r3E54uIiAx3ITkdAODpLIeDiedjsGfGglhbW2P48OGYPXs2rl69Cnd3d8yYMQNXrlyBq6sr6tevj48++ghA/tiT33//HWPHjkXLli0hlUpRt25dNGvWDAAwaNAgJCQk4J133oFMJsOoUaN06pVxcnLC7NmzcenSJUilUjRq1AhbtmwptueqX79+6Ny5M1q0aIEqVapobYuNjcWIESPQtWtX5ObmokWLFtiyZQtnMhERmZh68G+IlxOATJPGwmTGTK1YsaLQ8g8//BAffvghAGDEiBEYMWJEkXWop8IXRiaTYdGiRZgxYwacnZ0LTUaSkpIKlA0ZMgRDhgwp8piF3T2jU6dOhZYDQIUKFfDdd98VWR8REZmGOpkJ83ICFMkmjYWXmYiIiEhv527nX2bK75kxLSYzREREpBelSuBi8pOXmUyLyQwRERHp5er9TGQrVLCVWcG/kr2pw2EyQ0RERPpRj5ep4eUMqZVht+ExJiYzREREpBfN4F9v019iApjMEBERkZ7UyUyot7OJI8nHZIaIiIj0cv7fmUxMZoiIiMjsPMrMRXJaNoCyMZMJYDJDREREelBfYqpS0R5OtmVjNXYmM0RERKSzc5rxMmWjVwZgMmP2kpOTMWLECAQFBcHW1haenp5o1qwZYmJikJWVZerwiIjIwpwrY4N/Ad6byaxduXIFzZo1g6urK6ZPn47atWtDLpfj9OnTWLZsGSpXroxu3bqZOkwiIrIgZW3wL8CeGbP27rvvwtraGsePH0evXr0QGhqKatWqoXv37vjtt98QGRkJAJgzZw5q164NBwcH+Pn54d1330VGRoamnkmTJqFu3bpadc+bNw/VqlXTPN6zZw8aN24MBwcHuLq6olmzZrh27RoA4OTJk3jppZfg5OQEZ2dnNGjQAMePHy/9E0BERM9Vbp4Kl+/mJzNhZSiZYc/M04QAFDpenlGp8vfNlQKF3FVabzJ7QKLbSooPHjzAjh07MH36dDg4OBS6j+TfuqysrPDVV1+hatWquHLlCt5991188MEHWLx4sU7HysvLQ48ePTBkyBD88MMPyM3NxdGjRzX19+vXD/Xq1UNMTAykUikSEhIgk5WNQWFERGQ8ifcyoFAKOMmt4VvBztThaDCZeZoiC5juo9OuVgBcjXnsj24BNoUnJk+7fPkyhBCoUaOGVrmbmxuys/OnzA0bNgyzZs3CyJEjNdsDAgIwbdo0DB06VOdkJi0tDampqejatSsCAwMBAKGhoZrt169fx9ixYxESEgIACA4O1qleIiIyL+qZTCHeTpo/aMsCXmayMEePHkVCQgJq1qyJnJwcAMDOnTvRpk0bVK5cGU5OThgwYAAePHig8wDhihUrIjo6Gh06dEBkZCTmz5+P27dva7aPHj0ab775Jtq2bYuZM2ciMTGxVNpGRESm9d9tDMrOJSaAPTMFyezze0h0oFKpkJaeDmcnJ1gZ6zKTjoKCgiCRSHDx4kWtcvU4Fzu7/O6/pKQkdO3aFe+88w4+++wzVKxYEfv378fgwYORm5sLe3t7WFlZQQihVY9CodB6HBsbi/feew/btm3Djz/+iE8++QTx8fF44YUXMGnSJPTt2xe//fYbtm7diokTJ2LNmjV4+eWXDTkLRERURpXFwb8Ae2YKkkjyL/Xo+iOz12//4n706LKrVKkS2rVrh4ULFyIzM7PI/U6cOAGVSoUvv/wSL7zwAqpXr45bt7STNXd3dyQnJ2slNAkJCQXqqlevHsaPH4+DBw+iVq1aiIuL02yrXr06Ro0ahR07duCVV15BbGyszm0hIqKyTwhR5u7JpMZkxowtXrwYeXl5aNiwIX788UecP38eFy9exOrVq3HhwgVIpVIEBQVBoVBgwYIFuHLlClatWoUlS5Zo1dOqVSvcu3cPs2fPRmJiIhYtWoStW7dqtl+9ehXjx4/HoUOHcO3aNezYsQOXLl1CaGgoHj9+jOHDh2PPnj24du0aDhw4gGPHjmmNqSEiIvN3Nz0HDzJzYSUBapSR2xioMZkxY4GBgfjrr7/Qtm1bjB8/HuHh4WjYsCEWLFiAMWPGYOrUqQgPD8ecOXMwa9Ys1KpVC99//z1mzJihVU9oaCgWL16MRYsWITw8HEePHsWYMWM02+3t7XHhwgX07NkT1atXx1tvvYVhw4bh7bffhlQqxYMHDzBw4EBUr14dvXr1QqdOnTB58uTnfTqIiKgUqRfLq+rmAFuZ1MTRaOOYGTPn7e2NBQsWYMGCBUXuM2rUKIwaNUqrbMCAAVqPhw4diqFDh2qVffjhh0hLS4Onpyc2bNhQaN02Njb44YcfDIyeiIjMRVm9xASwZ4aIiIh0UFYH/wJMZoiIiEgHZXVaNsBkhoiIiJ4hW6HElXv5t8EJ82EyQ0RERGbm7zvpUAmgooMNPJzkpg6nACYzREREVKz/Bv+WrdsYqDGZISIiomKdu/VvMuNV9i4xAUxmiIiI6BnK8kwmgMkMERERFUMIgfPJZXeNGYDJDBERERXjn0ePkZ6dB5lUgiAPR1OHUygmM0RERFQk9eDfIA8n2FiXzbShbEZFzxQdHQ2JRIKZM2dqlW/cuLFMjjQnIiLz9N94mbJ1c8knmTSZiYmJQZ06deDs7AxnZ2dERERo3a05Ozsbw4YNQ6VKleDo6IiePXvizp07Joy4bLG1tcWsWbPw6NEjU4dCREQWqiyv/Ktm0mTG19cXM2fOxIkTJ3D8+HG0bt0a3bt3x9mzZwHk3yDx119/xdq1a7F3717cunULr7zyiilDLlPatm0LLy+vAnfBVps0aRLq1q2rVTZv3jwEBARoHkdHR6NHjx6YPn06PD094erqiilTpiAvLw8ffPABqlatiipVqiA2NlbznKSkJEgkEqxZswZNmzaFra0tatWqhb179wLIHywWFBSEL774QuvYCQkJkEgkuHz5snFOABERlbqyPvgXMPFdsyMjI7Uef/bZZ4iJicHhw4fh6+uL5cuXIy4uDq1btwYAxMbGIjQ0FIcPH8YLL7xQKjEJIfA477FO+6pUKjzOewxrhTWsrEqeF9pZ2+l1iUgqlWL69Ono27cv3nvvPfj6+hp03N9//x2+vr7Yt28fDhw4gMGDB+PgwYNo3rw5du7ciS1btuDtt99Gu3bttI4xduxYzJs3D2FhYZgzZw4iIyNx9epVVKpUCYMGDUJsbCzGjBmj2T82NhYtWrRAUFCQQXESEdHzlZ6twLUHWQCYzOhEqVRi7dq1yMzMREREBE6cOAGFQoG2bdtq9gkJCUGVKlVw6NChIpOZnJwc5OTkaB6npeVnlAqFAgqFQmtfhUIBIQRUKhVUKhUAIEuRhYg1EcZunk4O9T4Ee5m9TvsKISCEQPfu3VG3bl1MmDAB33zzjaYdKpUKQgjNv5983pNlQghUrFgR8+bNg5WVFYKDgzF79mxkZWXhww8/RHp6OsaNG4dZs2Zh37596N27t+a5w4YNw8svvwwAWLRoEbZt24ZvvvkGY8eOxcCBAzFhwgQcPnwYjRs3hkKhQFxcHGbPnq0VT2lQt12hUEAqlRa7r/p34unfDUvB9pk/S28j21e2nf0nfxiDp5McTjaSQttRWm3Upz6TJzOnT59GREQEsrOz4ejoiA0bNiAsLAwJCQmwsbGBq6ur1v6enp5ITk4usr4ZM2Zg8uTJBcp37NgBe3vtRMHa2hpeXl7IyMhAbm4uAOjcK1Ma0tPTkWedp9O+CoUCeXl5SEtLwyeffILu3bvj7bffxuPH+fGnpaUhJycHSqVSk9AB+eOQVCqVVpJXvXp1ZGRkaPapVKkSqlevjvT0/EFfWVlZqFChAm7cuIG0tDTNvrVr19aqOzw8HKdOnUJaWhocHR3Rvn17LF26FCEhIfj111+Rk5ODDh06aD2nNOTm5uLx48fYt28f8vJ0O5/x8fGlGpOpsX3mz9LbyPaVTX8kSwBIUVH6GFu2bCl2X2O3MSsrS+d9TZ7M1KhRAwkJCUhNTcW6desQFRWlGXthiPHjx2P06NGax2lpafDz80P79u3h7KzdRZadnY0bN27A0dERtra2AAAn4YRDvQ/pfLz09HQ4ORlnhLc+l5lkMhmsra3h7OyMTp06oX379pg+fTqioqIAAM7OzrCzs4OVlZVWu6VSqVaZTCaDnZ2d1j4ymQwODg5wcnLStE8qlcLGxgbOzs5wdMxfZ8DBwUHredbW1pDJZJqyt99+G1FRUVi4cCF+/PFH9OrVC15eXiU7STrIzs6GnZ0dWrRooXldi6JQKBAfH4927dpBJpOVemzPG9tn/iy9jWxf2Xbwl3PA1X/QonYgOrcPLnSf0mqjPn/4mjyZsbGx0YyhaNCgAY4dO4b58+fj9ddfR25uLlJSUrR6Z+7cuVPsF6JcLodcXvCOnjKZrMBJViqVkEgksLKy0hrz4ijVbVEglUqFPOs82MvsjTJmRh8SiUQTOwDMmjULdevWRUhICADAysoKHh4eSE5O1uwLACdPntRsL6yep+tX/1v9/yfP1dGjR9GqVSsAQF5eHv78808MHz5cs71r165wcHDA0qVLsX37duzbt++5nCcrKytIJJJCX/Oi6LOvOWL7zJ+lt5HtK5su3snvia/l6/rM+I3dRn3qKnPrzKhUKuTk5KBBgwaQyWTYtWuXZtvFixdx/fp1RESYZkxLWVa7dm3069cPX331laasVatWuHfvHmbPno3ExEQsWrRIa+p7SS1atAgbNmzAhQsXMGzYMDx69AiDBg3SbJdKpYiOjsb48eMRHBzM142IyIwoVQIXk8v2PZnUTJrMjB8/Hvv27UNSUhJOnz6N8ePHY8+ePejXrx9cXFwwePBgjB49Grt378aJEyfwxhtvICIiotRmMpm7KVOmaA2uDQ0NxeLFi7Fo0SKEh4fj6NGjWrOLSmrmzJmYOXMmwsPDsX//fmzatAlubm5a+wwePBi5ubl44403jHZcIiIqfdceZOKxQglbmRWqujmYOpximfQy0927dzFw4EDcvn0bLi4uqFOnDrZv34527doBAObOnQsrKyv07NlTM3h08eLFpgy5zFixYkWBsoCAAK2ZXAAwdOhQDB06VKvso48+KraePXv2ANCeBZWUlFRgv9DQUBw5cqTYOG/evAmZTIaBAwcWux8REZUt6pV/a3g6QWpVtleWN2kys3z58mK329raYtGiRVi0aNFzioiMJScnB/fu3cOkSZPw2muvwdPT09QhERGRHs7dTgVQ9i8xAWVwzAxZhh9++AH+/v5ISUnB7NmzTR0OERHp6b97MpX9ZMbks5nI/AQEBGgW3ytKdHQ0oqOjn09ARERkdOp7MplDMsOeGSIiItKSkpWL26nZAICQMny3bDUmM8AzexnIvPD1JCIqmXP/9sr4VbSDs23ZXx+nXCcz6gV59Fkymco+9etpjgtUERGVBZrxMl5l/xITUM7HzEilUri6uuLu3bsAAHt7e73uWq1SqZCbm4vs7OznvgLw82Bu7RNCICsrC3fv3oWrq+szbzJJRESFM6fxMkA5T2YAaG6NoE5o9CGEwOPHj2Fnp/s9lcyJubbP1dX1udwDiojIUjGZMTMSiQTe3t7w8PDQ+/blCoUC+/btQ4sWLSzykoY5tk8mk7FHhoioBBRKFS79e0+mMCYz5kUqler9JSiVSpGXlwdbW1uz+bLXh6W3j4iICkq8l4FcpQqOcmv4VrAzdTg6KfsDIYiIiOi5UV9iCvFyglUZv42BGpMZIiIi0jCnlX/VmMwQERGRhrpnJsyHyQwRERGZIXObyQQwmSEiIqJ/3U3Pxv2MXFhJgBqeZf82BmpMZoiIiAjAf+NlAtwcYGdjPstcMJkhIiIiAMC5W+Z3iQlgMkNERET/0gz+ZTJDRERE5ui/wb/mM14GYDJDREREALIVSly5nwmAl5mIiIjIDF26kwGlSqCCvQxezramDkcvTGaIiIhIa30ZicQ8bmOgxmSGiIiIcM4MF8tTYzJDREREZrnyrxqTGSIionJOCPFEz4x5zWQCmMwQERGVezdTHiM9Ow/WVhIEeTiaOhy9MZkhIiIq59S3MQjycITc2nxuY6DGZIaIiKicM+fxMgCTGSIionLPXG9joMZkhoiIqJxjzwwRERGZrcycPFx7mAXAPGcyAUxmiIiIyrULyekQAvBwkqOSo9zU4RiEyQwREVE5Zs4r/6oxmSEiIirHzH28DMBkhoiIqFw7b8Yr/6oxmSEiIiqnVCqBi8n5C+aZ67RsgMkMERFRuXXtYRaycpWQW1uhqpuDqcMxWImTmZycHGPEQURERM+Z+hJTDS8nWEvNt39D78i3bt2KqKgoVKtWDTKZDPb29nB2dkbLli3x2Wef4datW6URJxERERmZZryMl/leYgL0SGY2bNiA6tWrY9CgQbC2tsa4ceOwfv16bN++Hd988w1atmyJnTt3olq1ahg6dCju3bv3zDpnzJiBRo0awcnJCR4eHujRowcuXryotU+rVq0gkUi0foYOHap/S4mIiEjLuVvmP/gXAKx13XH27NmYO3cuOnXqBCurgjlQr169AAA3b97EggULsHr1aowaNarYOvfu3Ythw4ahUaNGyMvLw0cffYT27dvj3LlzcHD479rdkCFDMGXKFM1je3t7XcMmIiKiIljCtGxAj2Tm0KFDOu1XuXJlzJw5U6d9t23bpvV4xYoV8PDwwIkTJ9CiRQtNub29Pby8vHSqMycnR2scT1pa/gulUCigUCh0qkNX6vqMXW9ZYentAyy/jWyf+bP0NrJ9ppOSpcCt1GwAQJCbncExllYb9alPIoQQJT2gUqnE6dOn4e/vjwoVKhhcz+XLlxEcHIzTp0+jVq1aAPIvM509exZCCHh5eSEyMhKffvppkb0zkyZNwuTJkwuUx8XFsUeHiIjoX5dSJVh4ToqKcoGJ9ZWmDqeArKws9O3bF6mpqXB2Lr7nyKBkZuTIkahduzYGDx4MpVKJli1b4uDBg7C3t8fmzZvRqlUrvYNWqVTo1q0bUlJSsH//fk35smXL4O/vDx8fH5w6dQrjxo1D48aNsX79+kLrKaxnxs/PD/fv33/mydCXQqFAfHw82rVrB5lMZtS6ywJLbx9g+W1k+8yfpbeR7TOdFYeu4bMtF9EmxB1L+tUzuJ7SamNaWhrc3Nx0SmZ0vsz0pHXr1qF///4AgF9//RVXr17FhQsXsGrVKnz88cc4cOCA3nUOGzYMZ86c0UpkAOCtt97S/Lt27drw9vZGmzZtkJiYiMDAwAL1yOVyyOUFb5Qlk8lK7RepNOsuCyy9fYDlt5HtM3+W3ka27/n7+04mAKBmZVejxGbsNupTl0GTyu/fv68Zw7Jlyxa89tprmplOp0+f1ru+4cOHY/Pmzdi9ezd8fX2L3bdJkyYA8i9JERERkWHOJ+ePKQ0z85lMgIHJjKenJ86dOwelUolt27ahXbt2APKvb0mlUp3rEUJg+PDh2LBhA37//XdUrVr1mc9JSEgAAHh7exsSOhERUbmnUKrw950MAOY/kwkw8DLTG2+8gV69esHb2xsSiQRt27YFABw5cgQhISE61zNs2DDExcXhl19+gZOTE5KTkwEALi4usLOzQ2JiIuLi4tC5c2dUqlQJp06dwqhRo9CiRQvUqVPHkNCJiIjKvSv3MpGbp4KDjRR+Fcx/coxBycykSZNQq1Yt3LhxA6+99ppmjIpUKsWHH36ocz0xMTEAUGDAcGxsLKKjo2FjY4OdO3di3rx5yMzMhJ+fH3r27IlPPvnEkLCJiIgI/60vE+LtDCsriYmjKTmDkhkAePXVVwuURUVF6VXHsyZS+fn5Ye/evXrVSURERMX7b7E88x8vA+gxZmbNmjU6V3rjxg2DZjQRERFR6TtnISv/qumczMTExCA0NBSzZ8/G+fPnC2xPTU3Fli1b0LdvX9SvXx8PHjwwaqBERERkHOdvpwOwnGRG58tMe/fuxaZNm7BgwQKMHz8eDg4O8PT0hK2tLR49eoTk5GS4ubkhOjoaZ86cgaenZ2nGTURERAa4l56D+xk5kEiAEC/LuMyk15iZbt26oVu3brh//z7279+Pa9eu4fHjx3Bzc0O9evVQr169Qm9CSURERGWDerxM1UoOsLcxeOhsmWJQK9zc3NCjRw8jh0JERESlzVLulP0kdqMQERGVI+csbCYTwGSGiIioXGHPDBEREZmtbIUSiffybzDJZIaIiIjMzuW7GVCqBFzsZPB2sTV1OEbDZIaIiKiceHK8jERi/rcxUDNoNpNSqcSKFSuwa9cu3L17FyqVSmv777//bpTgiIiIyHjU42XCvF1MHIlxGZTMjBgxAitWrECXLl1Qq1Yti8ruiIiILJWl3ZNJzaBkZs2aNfjpp5/QuXNnY8dDREREpUAIYXG3MVAzaMyMjY0NgoKCjB0LERERlZJbqdlIfayAtZUEwZ6Opg7HqAxKZt5//33Mnz8fQghjx0NERESl4Pyt/EtMge6OkFtLTRyNcRl0mWn//v3YvXs3tm7dipo1a0Imk2ltX79+vVGCIyIiIuOw1PEygIHJjKurK15++WVjx0JERESl5Hyy5a38q2ZQMhMbG2vsOIiIiKgUWergX8DAZEbt3r17uHjxIgCgRo0acHd3N0pQREREZDxZuXlIemB5tzFQM2gAcGZmJgYNGgRvb2+0aNECLVq0gI+PDwYPHoysrCxjx0hEREQlcCE5HUIA7k5yuDvJTR2O0emUzMybNw+7du3SPB49ejT27t2LX3/9FSkpKUhJScEvv/yCvXv34v333y+1YImIiEh/lnin7CfplMw0b94cQ4YMwapVqwAAP//8M5YvX45OnTrB2dkZzs7O6Ny5M77++musW7euVAMmIiIi/Zy7ZbkzmQAdk5kGDRrgyJEjiIuLAwBkZWXB09OzwH4eHh68zERERFTG/HdPpnLcMwMA7u7u2LJlCwAgIiICEydORHZ2tmb748ePMXnyZERERBg/SiIiIjKISiVwIdlyZzIBes5mUt9Qcv78+ejQoQN8fX0RHh4OADh58iRsbW2xfft240dJREREBrn+MAtZuUrYWFuhmpuDqcMpFQZNza5VqxYuXbqE77//HhcuXAAA9OnTB/369YOdnZ1RAyQiIiLDqS8xVfd0hLXUoEnMZZ7B68zY29tjyJAhxoyFiIiIjMzSx8sAeiQzmzZtQqdOnSCTybBp06Zi9+3WrVuJAyMiIqKSO2fBK/+q6ZzM9OjRA8nJyfDw8ECPHj2K3E8ikUCpVBojNiIiIiohS19jBtAjmVGpVIX+m4iIiMqm1CwFbqY8BgCEelluMmOZI4GIiIhIc6fsyq52cLGXmTia0mNQMvPee+/hq6++KlC+cOFCjBw5sqQxERERkRH8d4nJMlf+VTMomfn555/RrFmzAuVNmzbl7QyIiIjKiPIwXgYwMJl58OABXFxcCpQ7Ozvj/v37JQ6KiIiISu78vzOZLHlaNmBgMhMUFIRt27YVKN+6dSuqVatW4qCIiIioZPKUKly8Y/nTsgEDF80bPXo0hg8fjnv37qF169YAgF27duHLL7/EvHnzjBkfERERGeDq/Uzk5qngYCNFlYr2pg6nVBmUzAwaNAg5OTn47LPPMHXqVABAQEAAYmJiMHDgQKMGSERERPo79+94mRpeTrCykpg4mtJl8NTsd955B//88w/u3LmDtLQ0XLlyRe9EZsaMGWjUqBGcnJw0i/FdvHhRa5/s7GwMGzYMlSpVgqOjI3r27Ik7d+4YGjYREVG5cK6cDP4FjLDOjLu7OxwdHQ167t69ezFs2DAcPnwY8fHxUCgUaN++PTIzMzX7jBo1Cr/++ivWrl2LvXv34tatW3jllVdKGjYREZFFO18ObmOgZtBlpqpVq0IiKbrL6sqVKzrV8/Qg4hUrVsDDwwMnTpxAixYtkJqaiuXLlyMuLk4zNic2NhahoaE4fPgwXnjhBUPCJyIisnjlZVo2YGAy8/TCeAqFAn/99Re2bduGsWPHGhxMamoqAKBixYoAgBMnTkChUKBt27aafUJCQlClShUcOnSo0GQmJycHOTk5msdpaWmaGBUKhcGxFUZdn7HrLSssvX2A5beR7TN/lt5Gtq90PMjIwb30HEgkQGAl21I9fmm1UZ/6JEIIYawDL1q0CMePH0dsbKzez1WpVOjWrRtSUlKwf/9+AEBcXBzeeOMNreQEABo3boyXXnoJs2bNKlDPpEmTMHny5ALlcXFxsLe37NHcREREAHAhRYKY81K42wp8Us88b/6clZWFvn37IjU1Fc7OxfcuGdQzU5ROnTph/PjxBiUzw4YNw5kzZzSJjKHGjx+P0aNHax6npaXBz88P7du3f+bJ0JdCoUB8fDzatWsHmczy7nlh6e0DLL+NbJ/5s/Q2sn2l49b+JOD832gQ6IXOncNL9Vil1Ub1lRVdGDWZWbduneYSkT6GDx+OzZs3Y9++ffD19dWUe3l5ITc3FykpKXB1ddWU37lzB15eXoXWJZfLIZfLC5TLZLJS+0UqzbrLAktvH2D5bWT7zJ+lt5HtM66/7+ZPpKnp4/LcjmvsNupTl0HJTL169bQGAAshkJycjHv37mHx4sU61yOEwP/+9z9s2LABe/bsQdWqVbW2N2jQADKZDLt27ULPnj0BABcvXsT169cRERFhSOhEREQWrzwN/gUMTGZ69Oih9djKygru7u5o1aoVQkJCdK5n2LBhiIuLwy+//AInJyckJycDAFxcXGBnZwcXFxcMHjwYo0ePRsWKFeHs7Iz//e9/iIiI4EwmIiKiQuTkKXH5bgYAINSHyUyRJk6caJSDx8TEAABatWqlVR4bG4vo6GgAwNy5c2FlZYWePXsiJycHHTp00Kv3h4iIqDy5dCcDeSoBZ1tr+LjYmjqc58KgZGbLli2QSqXo0KGDVvn27duhUqnQqVMnnerRZSKVra0tFi1ahEWLFhkSKhERUbny5CWm4taEsyQGrQD84YcfQqksONVLCIEPP/ywxEERERGRYcrTyr9qBiUzly5dQlhYWIHykJAQXL58ucRBERERkWHUPTNh5WS8DGBgMuPi4lLoLQsuX74MBweHEgdFRERE+hNC4Hzyv8kMe2aK1717d4wcORKJiYmassuXL+P9999Ht27djBYcERER6S45LRspWQpIrSQI8jDsJtDmyKBkZvbs2XBwcEBISAiqVq2KqlWrIjQ0FJUqVcIXX3xh7BiJiIhIB+pLTIHuDrCVSU0czfNj0GwmFxcXHDx4EPHx8Th58iTs7OxQp04dtGjRwtjxERERkY7O3Spfi+WpGXw7A4lEgvbt26NFixaQy+XlZvoXERFRWVUeZzIBBl5mUqlUmDp1KipXrgxHR0dcvXoVAPDpp59i+fLlRg2QiIiIdFPebmOgZlAyM23aNKxYsQKzZ8+GjY2NprxWrVr45ptvjBYcERER6SYrNw9XH+TfYDLU28nE0TxfBiUz3333HZYtW4Z+/fpBKv1vgFF4eDguXLhgtOCIiIhINxeT0yEE4OYoh4dT+biNgZpByczNmzcRFBRUoFylUkGhUJQ4KCIiItLPf+NlylevDGBgMhMWFoY//vijQPm6detQr169EgdFRERE+tGs/FvOxssABs5mmjBhAqKionDz5k2oVCqsX78eFy9exHfffYfNmzcbO0YiIiJ6hvI6+BcowQrAv/76K3bu3AkHBwdMmDAB58+fx6+//op27doZO0YiIiIqhkolynUyY/A6M82bN0d8fLwxYyEiIiID3HiUhcxcJWykVqjmXv7ukWhQzwwRERGVHepemWBPR8ik5e+rXeeemYoVK+Lvv/+Gm5sbKlSoUOyKv46OjqhZsyZmzZqFOnXqGCVQIiIiKty5crryr5rOyczcuXPh5JQ/3WvevHnF7puTk4MtW7bgjTfewIkTJ0oUIBERERWvPM9kAvRIZqKiogr9d1E6deqEBg0aGBYVERER6aw8D/4F9Bwzc/ToUSiVyiK35+Tk4KeffgIA+Pn54e7duyWLjoiIiIqVlq3AP48eAyi/PTN6JTMRERF48OCB5rGzszOuXLmieZySkoI+ffoYLzoiIiIq1oV/x8v4uNjCxV5m4mhMQ69kRghR7OOiyoiIiKh0nLuVCqD8XmICSmFqdnGznIiIiMi4zpfzmUwA15khIiIya+eTy/fgX8CAFYDPnTuH5ORkAPmXlC5cuICMjAwAwP37940bHRERERUpT6nCxeTye7dsNb2TmTZt2miNi+natSuA/MtLQgheZiIiInpOkh5kIidPBXsbKfwrlb/bGKjplcxcvXq1tOIgIiIiPalX/q3h5QSpVfntTNArmfH39y+tOIiIiEhP5X2xPDUOACYiIjJT524xmQGYzBAREZmt/+7JVH4H/wJMZoiIiMzSg4wc3E3PAQDU8GLPDBEREZkZ9WJ5/pXs4SjXe3KyRTE4mcnLy8POnTuxdOlSpKfnn9Bbt25p1pwhIiKi0qMZ/FvOe2UAA9aZAYBr166hY8eOuH79OnJyctCuXTs4OTlh1qxZyMnJwZIlS4wdJxERET1BM17Gh8mMQT0zI0aMQMOGDfHo0SPY2dlpyl9++WXs2rXLaMERERFR4c5xWraGQT0zf/zxBw4ePAgbGxut8oCAANy8edMogREREVHhcvNUSLyXP6yjPN/GQM2gnhmVSgWlUlmg/J9//oGTE08qERFRabp0Nx0KpYCzrTUqu9o9+wkWzqBkpn379pg3b57msUQiQUZGBiZOnIjOnTsbKzYiIiIqhHomU4i3M++JCAOTmS+//BIHDhxAWFgYsrOz0bdvX80lplmzZulV1759+xAZGQkfHx9IJBJs3LhRa3t0dDQkEonWT8eOHQ0Jm4iIyCL8t1gex8sABo6Z8fX1xcmTJ7FmzRqcOnUKGRkZGDx4MPr166c1IFgXmZmZCA8Px6BBg/DKK68Uuk/Hjh0RGxureSyXyw0Jm4iIyCL8d08mDu0ADExmAMDa2hr9+/cvcQCdOnVCp06dit1HLpfDy8urxMciIiIyd0II3mDyKTonM5s2bdK50m7duhkUTFH27NkDDw8PVKhQAa1bt8a0adNQqVKlQvfNyclBTk6O5nFaWv4LrlAooFAojBqXuj5j11tWWHr7AMtvI9tn/iy9jWyf/pLTsvEoSwGplQRVK9qa/NyV1muoT30SIYTQZUcrK+3hNRKJBE8/VT0IqbCZTjoFI5Fgw4YN6NGjh6ZszZo1sLe3R9WqVZGYmIiPPvoIjo6OOHToEKRSaYE6Jk2ahMmTJxcoj4uLg729vUFxERERlRVnH0mw7IIUXnYC4+sa9n1rDrKystC3b1+kpqbC2bn4Hiidk5kn7dy5E+PGjcP06dMREREBADh06BA++eQTTJ8+He3atTMo8MKSmadduXIFgYGB2LlzJ9q0aVNge2E9M35+frh///4zT4a+FAoF4uPj0a5dO8hkMqPWXRZYevsAy28j22f+LL2NbJ/+luy9gi93XkbX2l6Y26uOUeosidJ6DdPS0uDm5qZTMmPQmJmRI0diyZIlePHFFzVlHTp0gL29Pd566y2cP3/ekGp1Uq1aNbi5ueHy5cuFJjNyubzQAcIymazU3iilWXdZYOntAyy/jWyf+bP0NrJ9urtwNxMAULOya5k6Z8Z+DfWpy6Cp2YmJiXB1dS1Q7uLigqSkJEOq1Nk///yDBw8ewNvbu1SPQ0REVBZxJlNBBiUzjRo1wujRo3Hnzh1N2Z07dzB27Fg0btxYr7oyMjKQkJCAhIQEAMDVq1eRkJCA69evIyMjA2PHjsXhw4eRlJSEXbt2oXv37ggKCkKHDh0MCZ2IiMhsPc5VIul+fs8M15j5j0GXmb799lu8/PLLqFKlCvz8/AAAN27cQHBwcIFF757l+PHjeOmllzSPR48eDQCIiopCTEwMTp06hZUrVyIlJQU+Pj5o3749pk6dyrVmiIio3Ll4Jx0qAVRysIG7E78H1QxKZoKCgnDq1CnEx8fjwoULAIDQ0FC0bdtW72WVW7VqVWBW1JO2b99uSIhEREQW58n1ZXgbg/8YvGieRCJB+/bt0b59e2PGQ0REREXQ3MbAh5eYnmTQmBkiIiJ6/jj4t3BMZoiIiMyASiU0d8vmbQy0MZkhIiIyA/88eoyMnDzYSK0Q6O5o6nDKFCYzREREZuDcv5eYgjwcIZPy6/tJBg8AViqV2Lhxo2a135o1a6Jbt26F3i+JiIiISoZ3yi6aQcnM5cuX0aVLF/zzzz+oUaMGAGDGjBnw8/PDb7/9hsDAQKMGSUREVN5x8G/RDOqneu+991CtWjXcuHEDf/75J/78809cv34dVatWxXvvvWfsGImIiMq988n/Tstmz0wBBvXM7N27F4cPH0bFihU1ZZUqVcLMmTPRrFkzowVHREREQHq2AjcePgbAy0yFMahnRi6XIz09vUB5RkYGbGxsShwUERER/edCcv53rreLLSo48Hv2aQYlM127dsVbb72FI0eOQAgBIQQOHz6MoUOHolu3bsaOkYiIqFzj4N/iGZTMfPXVVwgMDERERARsbW1ha2uLZs2aISgoCPPnzzd2jEREROXauVsc/Fscg8bMuLq64pdffsGlS5dw/vx5SCQShIaGIigoyNjxERERlXvsmSmewevMAEBwcLAmgeHdO4mIiIxPqRK4eIe3MSiOwUsILl++HLVq1dJcZqpVqxa++eYbY8ZGRERU7l29n4lshQq2MisEVHIwdThlkkE9MxMmTMCcOXPwv//9DxEREQCAQ4cOYdSoUbh+/TqmTJli1CCJiIjKK/UlphpezpBa8SpIYQxKZmJiYvD111+jT58+mrJu3bqhTp06+N///sdkhoiIyEjUyQwXyyuaQZeZFAoFGjZsWKC8QYMGyMvLK3FQRERElO+/ZIYzmYpiUDIzYMAAxMTEFChftmwZ+vXrV+KgiIiIKN/52xz8+ywGz2Zavnw5duzYgRdeeAEAcOTIEVy/fh0DBw7E6NGjNfvNmTOn5FESERGVQw8zc5Gclg0ACGEyUySDkpkzZ86gfv36AIDExEQAgJubG9zc3HDmzBnNfpyuTUREZDj1JaYqFe3hKC/RaioWzaAzs3v3bmPHQURERE/5b7E8jpcpjsHrzBAREVHpOseVf3ViUM9MdnY2FixYgN27d+Pu3btQqVRa2//880+jBEdERFSeqQf/clp28QxKZgYPHowdO3bg1VdfRePGjTk2hoiIyMhy81S4fJczmXRhUDKzefNmbNmyBc2aNTN2PERERAQg8V4GFEoBJ1tr+FawM3U4ZZpBY2YqV64MJycORiIiIiotmsG/Xs68AvIMBiUzX375JcaNG4dr164ZOx4iIiICcO4WZzLpyqDLTA0bNkR2djaqVasGe3t7yGQyre0PHz40SnBERETl1flkzmTSlUHJTJ8+fXDz5k1Mnz4dnp6e7P4iIiIyIiEEb2OgB4OSmYMHD+LQoUMIDw83djxERETl3t30HDzMzIWVBKjhxctMz2LQmJmQkBA8fvzY2LEQERER/lssr5q7I2xlUhNHU/YZlMzMnDkT77//Pvbs2YMHDx4gLS1N64eIiIgMd54r/+rFoMtMHTt2BAC0adNGq1wIAYlEAqVSWfLIiIiIyqn/xsvwEpMueKNJIiKiMoY9M/oxKJlp2bKlseMgIiIiANkKJa7cywDAezLpyuC7Zv/xxx/o378/mjZtips3bwIAVq1ahf379xstOCIiovLmYnI6VAKo6GADDye5qcMxCwYlMz///DM6dOgAOzs7/Pnnn8jJyQEApKamYvr06UYNkIiIqDz57xKTE9dx05FBycy0adOwZMkSfP3111qr/zZr1gx//vmnXnXt27cPkZGR8PHxgUQiwcaNG7W2CyEwYcIEeHt7w87ODm3btsWlS5cMCZuIiKjMe/KeTKQbg5KZixcvokWLFgXKXVxckJKSolddmZmZCA8Px6JFiwrdPnv2bHz11VdYsmQJjhw5AgcHB3To0AHZ2dmGhE5ERFSmqWcyhfkwmdGVQQOAvby8cPnyZQQEBGiV79+/H9WqVdOrrk6dOqFTp06FbhNCYN68efjkk0/QvXt3AMB3330HT09PbNy4Eb179zYkfCIiojJJCMF7MhnAoGRmyJAhGDFiBL799ltIJBLcunULhw4dwpgxY/Dpp58aLbirV68iOTkZbdu21ZS5uLigSZMmOHToUKHJTE5OjmYMDwDNIn4KhQIKhcJosanrfPL/lsbS2wdYfhvZPvNn6W1k+7T98+gx0rPzIJNKUMVVbhbnpbReQ33qkwghhL4HEEJg+vTpmDFjBrKysgAAcrkcY8aMwdSpU/Wt7r9gJBJs2LABPXr0AJB/D6hmzZrh1q1b8Pb21uzXq1cvSCQS/PjjjwXqmDRpEiZPnlygPC4uDvb29gbHRkREVNpOP5Tgm4tSVLYX+CC8fC9Am5WVhb59+yI1NRXOzsX3UhnUMyORSPDxxx9j7NixuHz5MjIyMhAWFgZHR0eDAjam8ePHY/To0ZrHaWlp8PPzQ/v27Z95MvSlUCgQHx+Pdu3aaQ2EthSW3j7A8tvI9pk/S28j26ct8fdE4GIiGlf3QefOtZ9DhCVXWq+hPrdHMiiZUbOxsUFYWFhJqiiWl5cXAODOnTtaPTN37txB3bp1C32OXC6HXF5wXr5MJiu1N0pp1l0WWHr7AMtvI9tn/iy9jWxfvot38xfLq1nZ1ezOh7FfQ33q0jmZeeWVV7BixQo4OzvjlVdeKXbf9evX6xxAcapWrQovLy/s2rVLk7ykpaXhyJEjeOedd4xyDCIiorLiv3sycfCvPnROZlxcXDSL97i4uBgtgIyMDFy+fFnz+OrVq0hISEDFihVRpUoVjBw5EtOmTUNwcDCqVq2KTz/9FD4+PppxNURERJYgPVuB6w/zx6EymdGPzslMbGwspkyZgjFjxiA2NtZoARw/fhwvvfSS5rF6vEtUVBRWrFiBDz74AJmZmXjrrbeQkpKCF198Edu2bYOtra3RYiAiIjK1i8n5vTJezrao6GBj4mjMi15jZiZPnoyhQ4cadVZQq1atUNyEKolEgilTpmDKlClGOyYREVFZ8+RtDEg/eq0AbMAsbiIiItLBOY6XMZjetzPgTa+IiIiM77+eGSYz+tJ7anb16tWfmdA8fPjQ4ICIiIjKG6VK4AJvY2AwvZOZyZMnG3U2ExERUXmX9CAT2QoVbGVWqOrmYOpwzI7eyUzv3r3h4eFRGrEQERGVS+pLTDU8nSC14nAOfek1ZobjZYiIiIyP42VKhrOZiIiITEy98m+YD5MZQ+h1mUmlUpVWHEREROUWe2ZKRu+p2URERGQ8jzJzcTs1GwAQ4sUF8wzBZIaIiMiE1L0yfhXt4GRrXnfKLiuYzBAREZnQOfUlJi9eYjIUkxkiIiITOs/bGJQYkxkiIiIT4uDfkmMyQ0REZCIKpQqX72YAAMKYzBiMyQwREZGJJN7LQK5SBSe5NXwr2Jk6HLPFZIaIiMhE1JeYQrydYMXbGBiMyQwREZGJcPCvcTCZISIiMpFztzj41xiYzBAREZmAEIIzmYyEyQwREZEJ3EvPwYPMXFhJgBqevI1BSTCZISIiMgH1yr8Bbg6ws5GaOBrzxmSGiIjIBDj413iYzBAREZmAerwMF8srOSYzREREJsBkxniYzBARET1n2QolrtzPBMDLTMbAZIaIiOg5+/tOOpQqgQr2Mng6y00djtljMkNERPScPbm+jETC2xiUFJMZIiKi54wzmYyLyQwREdFzdo4r/xoVkxkiIqLnSPs2Blz51xiYzBARET1HN1MeIz07DzKpBMEeTGaMgckMERHRc6QeLxPo7ggba34NGwPPIhER0XPExfKMj8kMERHRc3TuFgf/GhuTGSIioufofDKTGWNjMkNERPScZOTk4dqDLACcyWRMTGaIiIiek4v/9sp4OMlRyZG3MTCWMp/MTJo0CRKJROsnJCTE1GERERHp7RxX/i0V1qYOQBc1a9bEzp07NY+trc0ibCIiIi2amUw+TGaMySyyAmtra3h5eZk6DCIiohI5z9sYlAqzSGYuXboEHx8f2NraIiIiAjNmzECVKlUK3TcnJwc5OTmax2lp+b84CoUCCoXCqHGp6zN2vWWFpbcPsPw2sn3mz9LbWJ7ap1QJXEzOv8wU7GZnMW0urddQn/okQghh1KMb2datW5GRkYEaNWrg9u3bmDx5Mm7evIkzZ87AyangSPBJkyZh8uTJBcrj4uJgb2//PEImIiIq4O5j4LMEa8gkArOaKCGVmDqisi0rKwt9+/ZFamoqnJ2L78kq88nM01JSUuDv7485c+Zg8ODBBbYX1jPj5+eH+/fvP/Nk6EuhUCA+Ph7t2rWDTCYzat1lgaW3D7D8NrJ95s/S21ie2rfz4gO89+Mp1K7sjPVDXzB1aEZTWq9hWloa3NzcdEpmzOIy05NcXV1RvXp1XL58udDtcrkccnnB6W4ymazU3iilWXdZYOntAyy/jWyf+bP0NpaH9v19N399mTBvF4tsq7FfQ33qKvNTs5+WkZGBxMREeHt7mzoUIiIinf03+JeL5RlbmU9mxowZg7179yIpKQkHDx7Eyy+/DKlUij59+pg6NCIiIp1xJlPpKfOXmf755x/06dMHDx48gLu7O1588UUcPnwY7u7upg6NiIhIJylZCtxKzQYAhHKNGaMr88nMmjVrTB0CERFRiVy8kz8l27eCHZxtLW+8jKmV+ctMRERE5u58Mm9jUJqYzBAREZWy87wnU6liMkNERFTKLvzbMxPGmUylgskMERFRKVKqgEt3MwCwZ6a0MJkhIiIqRXeyAYVSwMFGCr8KvK1OaWAyQ0REVIpuZebfhCnE2xlWVrwhU2lgMkNERFSKbmblJzBhvMRUapjMEBERlaJbmfn/53iZ0sNkhoiIqBSpe2Z4T6bSw2SGiIiolNxLz0G6QgKJBKjhxWSmtDCZISIiKiXq9WUCKtrD3qbM30HIbDGZISIiKgVJ9zPx3eHrAIAQ9sqUKqaJRERERnTmZipi9iZi6+nbUIn8subBbqYNysIxmSEiIiohIQQOXXmAmD2J+OPSfU15y+puqCNLxmsNKpswOsvHZIaIiMhAKpXAjnPJiNl7BSdvpAAArCRAZLgPhrYMRJCbHbZs2WLaIMsBJjNERER6ys1TYeNfN7FkXyKu3MtfSEZubYXXG/lhSPNq8KuYf9sChUJhyjDLDSYzREREOsrIycOao9fxzR9XkZyWDQBwsrVGVEQAopsFwM1RbuIIyycmM0RERM/wICMHKw8mYeWha0h9nN/b4uEkx5vNq6JP4ypwspWZOMLyjckMERFREf55lIVv/riKNceuI1uhAgBUdXPA2y2q4eX6lSG3lpo4QgKYzBARERVwMTkdS/cm4peTt6D8d3517coueLdVINrX9IKUd78uU5jMEBER/et40kMs2ZuInefvaspeDHLDO60C0TSwEiQSJjFlEZMZIiIq14QQ2H3xLmL2JOJY0iMAgEQCdKrlhaEtA1HH19W0AdIzMZkhIqJyKU+pwuZTt7Fkb6LmHkoyqQQ96/virRbVUM3d0cQRkq6YzBARUbnyOFeJtSduYNm+K/jn0WMAgIONFP1e8MegZlXh5WJr4ghJX0xmiIioXEjNUmDV4STEHkjCg8xcAEAlBxu80SwAA14IgIs9p1ebKyYzRERk0e6kZWP5/qv4/vA1ZOYqAQC+FezwdotqeK2hH2xlnF5t7pjMEBGRRUq8l4Fle69gw183kavMXyMmxMsJ77QKRJfa3rCWWpk4QjIWJjNERGRRTv2Tgpg9idh2Nhkif4kYNA6oiHdaBaJVDXdOr7ZATGaIiMjsCSFw4PIDxOy9jAOXH2jK24Z6YGjLQDQMqGjC6Ki0MZkhIiKzpVQJbD+bjJg9iTh9MxUAILWSoHu4D95uGYgaXk4mjpCeByYzRERkdnLylNjw500s3XcFV+9nAgBsZVbo3agK3mxeFb4V7E0cIT1PTGaIiMhspGcr8MPR6/jmj6u4m54DAHCxkyGqaQCiIvxRyVFu4gjJFJjMEBFRmXc/IwcrDiThu0NJSMvOAwB4OdvizeZV0adxFTjI+XVWnvHVJyKiMuvGwyx8/ccV/HjsBnLy8qdXV3N3wNCWgehRtzJsrDm9mpjMEBFRGXT+dhqW7E3E5lO3oVTlz68O93PFOy0D0T7ME1ZWnF5N/2EyQ0REZYIQAseSHiFmz2XsvnhPU96iujuGtqyGiGqVuEYMFYrJDBERmZRKALsu3MXX+6/hxLVHAAArCdC5tjeGtgxErcouJo6QyjomM0REZHRCCOTkqZCRk4eM7Lz8/z/x7/R//52WlYMNJ6VIPpwAALCRWuHVhr54q3k1BLg5mLYRZDbMJplZtGgRPv/8cyQnJyM8PBwLFixA48aNTR0WEZFFUaqEJvHIzMlDevaTSYgCGTnKJ/6dvz3z3/3Tn0haMnPyoFAKHY8qgYNcigEvBGBQswB4ONuWahvJ8phFMvPjjz9i9OjRWLJkCZo0aYJ58+ahQ4cOuHjxIjw8PEwdHhGRSal7QZ5MPNJzFMjMUeYnHdn/9YRkPtEr8nRvSUZOHrL+vau0MTnYSOFoaw1HuTUcbWVwklvDQS6Fo1wGexsrZCRfxSd9X0IlZy50R4Yxi2Rmzpw5GDJkCN544w0AwJIlS/Dbb7/h22+/xYcffmiSmHJzc3D60iHcTUvEqb8PQGptFqdSL8q8PNxJTcTJi8Zvn9D1Dzb1/tDjCXrsmqdU4HZKIv688AekUpl+QZkB5b/tO3HhD1hbab+GRZ2mol+bok9sUc8p8hhF16TXFmWeEjdSEnHw9D5IpVYQAlD9G4xKCAjxX2yqf5+jEgIQ+eM0BPL3gXpfiH/L//2dE/mJgsC/+z9Rv/j3P6on9lHXJwot045H4KlY8e+2f+vEv7HkqZS4dv0mjv24Fo+VAo9z8vBYocLj3Dxk5arwWJGfgOj7nnqaNQBXAK7/vg2kVoC9jTXsbaSwlUlhL5PCzubfH7kUDjIpbGXWsJNZwc7GGg42VrC1yX9sL7OGvTz/eXYyKawKHbQrAORCoczD4YOXkZHihpx0y/scVSjzkP04EbduH4NManntA/LbmJN91aQxSIQo6VugdOXm5sLe3h7r1q1Djx49NOVRUVFISUnBL7/8orV/Tk4OcnJyNI/T0tLg5+eH+/fvw9nZ2WhxXbp2Cq8fiDZafURERObKTanCb72PQSYz3h+FaWlpcHNzQ2pq6jO/v8t8mnj//n0olUp4enpqlXt6euLChQsF9p8xYwYmT55coHzHjh2wtzdeF+bDjJuQq8p0HkhERPRc2AggPj7eqHVmZWXpvG+ZT2b0NX78eIwePVrzWN0z0759e6P2zADA64poxMfHo127dkbNRssKhUJh0e0DLL+NbJ/5s/Q2sn3mr7TamJaWpvO+ZT6ZcXNzg1QqxZ07d7TK79y5Ay8vrwL7y+VyyOUFbzQmk8lK7RepNOsuCyy9fYDlt5HtM3+W3ka2z/wZu4361FXmb2phY2ODBg0aYNeuXZoylUqFXbt2ISIiwoSRERERUVlQ5ntmAGD06NGIiopCw4YN0bhxY8ybNw+ZmZma2U1ERERUfplFMvP666/j3r17mDBhApKTk1G3bl1s27atwKBgIiIiKn/MIpkBgOHDh2P48OGmDoOIiIjKmDI/ZoaIiIioOExmiIiIyKwxmSEiIiKzxmSGiIiIzBqTGSIiIjJrTGaIiIjIrDGZISIiIrPGZIaIiIjMGpMZIiIiMmtmswKwoYQQAPS7lbiuFAoFsrKykJaWZpF3Q7X09gGW30a2z/xZehvZPvNXWm1Uf2+rv8eLY/HJTHp6OgDAz8/PxJEQERGRvtLT0+Hi4lLsPhKhS8pjxlQqFW7dugUnJydIJBKj1p2WlgY/Pz/cuHEDzs7ORq27LLD09gGW30a2z/xZehvZPvNXWm0UQiA9PR0+Pj6wsip+VIzF98xYWVnB19e3VI/h7Oxssb+kgOW3D7D8NrJ95s/S28j2mb/SaOOzemTUOACYiIiIzBqTGSIiIjJrTGZKQC6XY+LEiZDL5aYOpVRYevsAy28j22f+LL2NbJ/5KwtttPgBwERERGTZ2DNDREREZo3JDBEREZk1JjNERERk1pjMEBERkVljMmOAGTNmoFGjRnBycoKHhwd69OiBixcvmjoso4mJiUGdOnU0CyBFRERg69atpg6r1MycORMSiQQjR440dShGM2nSJEgkEq2fkJAQU4dlVDdv3kT//v1RqVIl2NnZoXbt2jh+/LipwzKagICAAq+hRCLBsGHDTB2aUSiVSnz66aeoWrUq7OzsEBgYiKlTp+p0Hx5zkZ6ejpEjR8Lf3x92dnZo2rQpjh07ZuqwDLZv3z5ERkbCx8cHEokEGzdu1NouhMCECRPg7e0NOzs7tG3bFpcuXXousTGZMcDevXsxbNgwHD58GPHx8VAoFGjfvj0yMzNNHZpR+Pr6YubMmThx4gSOHz+O1q1bo3v37jh79qypQzO6Y8eOYenSpahTp46pQzG6mjVr4vbt25qf/fv3mzoko3n06BGaNWsGmUyGrVu34ty5c/jyyy9RoUIFU4dmNMeOHdN6/eLj4wEAr732mokjM45Zs2YhJiYGCxcuxPnz5zFr1izMnj0bCxYsMHVoRvPmm28iPj4eq1atwunTp9G+fXu0bdsWN2/eNHVoBsnMzER4eDgWLVpU6PbZs2fjq6++wpIlS3DkyBE4ODigQ4cOyM7OLv3gBJXY3bt3BQCxd+9eU4dSaipUqCC++eYbU4dhVOnp6SI4OFjEx8eLli1bihEjRpg6JKOZOHGiCA8PN3UYpWbcuHHixRdfNHUYz9WIESNEYGCgUKlUpg7FKLp06SIGDRqkVfbKK6+Ifv36mSgi48rKyhJSqVRs3rxZq7x+/fri448/NlFUxgNAbNiwQfNYpVIJLy8v8fnnn2vKUlJShFwuFz/88EOpx8OeGSNITU0FAFSsWNHEkRifUqnEmjVrkJmZiYiICFOHY1TDhg1Dly5d0LZtW1OHUiouXboEHx8fVKtWDf369cP169dNHZLRbNq0CQ0bNsRrr70GDw8P1KtXD19//bWpwyo1ubm5WL16NQYNGmT0G+aaStOmTbFr1y78/fffAICTJ09i//796NSpk4kjM468vDwolUrY2tpqldvZ2VlUL6na1atXkZycrPV56uLigiZNmuDQoUOlfnyLv9FkaVOpVBg5ciSaNWuGWrVqmTocozl9+jQiIiKQnZ0NR0dHbNiwAWFhYaYOy2jWrFmDP//806yvXxenSZMmWLFiBWrUqIHbt29j8uTJaN68Oc6cOQMnJydTh1diV65cQUxMDEaPHo2PPvoIx44dw3vvvQcbGxtERUWZOjyj27hxI1JSUhAdHW3qUIzmww8/RFpaGkJCQiCVSqFUKvHZZ5+hX79+pg7NKJycnBAREYGpU6ciNDQUnp6e+OGHH3Do0CEEBQWZOjyjS05OBgB4enpqlXt6emq2lSYmMyU0bNgwnDlzxuIy7Ro1aiAhIQGpqalYt24doqKisHfvXotIaG7cuIERI0YgPj6+wF9NluLJv27r1KmDJk2awN/fHz/99BMGDx5swsiMQ6VSoWHDhpg+fToAoF69ejhz5gyWLFlikcnM8uXL0alTJ/j4+Jg6FKP56aef8P333yMuLg41a9ZEQkICRo4cCR8fH4t5DVetWoVBgwahcuXKkEqlqF+/Pvr06YMTJ06YOjSLw8tMJTB8+HBs3rwZu3fvhq+vr6nDMSobGxsEBQWhQYMGmDFjBsLDwzF//nxTh2UUJ06cwN27d1G/fn1YW1vD2toae/fuxVdffQVra2solUpTh2h0rq6uqF69Oi5fvmzqUIzC29u7QGIdGhpqUZfS1K5du4adO3fizTffNHUoRjV27Fh8+OGH6N27N2rXro0BAwZg1KhRmDFjhqlDM5rAwEDs3bsXGRkZuHHjBo4ePQqFQoFq1aqZOjSj8/LyAgDcuXNHq/zOnTuabaWJyYwBhBAYPnw4NmzYgN9//x1Vq1Y1dUilTqVSIScnx9RhGEWbNm1w+vRpJCQkaH4aNmyIfv36ISEhAVKp1NQhGl1GRgYSExPh7e1t6lCMolmzZgWWQ/j777/h7+9voohKT2xsLDw8PNClSxdTh2JUWVlZsLLS/gqSSqVQqVQmiqj0ODg4wNvbG48ePcL27dvRvXt3U4dkdFWrVoWXlxd27dqlKUtLS8ORI0eey3hLXmYywLBhwxAXF4dffvkFTk5OmuuBLi4usLOzM3F0JTd+/Hh06tQJVapUQXp6OuLi4rBnzx5s377d1KEZhZOTU4HxTQ4ODqhUqZLFjHsaM2YMIiMj4e/vj1u3bmHixImQSqXo06ePqUMzilGjRqFp06aYPn06evXqhaNHj2LZsmVYtmyZqUMzKpVKhdjYWERFRcHa2rI+riMjI/HZZ5+hSpUqqFmzJv766y/MmTMHgwYNMnVoRrN9+3YIIVCjRg1cvnwZY8eORUhICN544w1Th2aQjIwMrd7dq1evIiEhARUrVkSVKlUwcuRITJs2DcHBwahatSo+/fRT+Pj4oEePHqUfXKnPl7JAAAr9iY2NNXVoRjFo0CDh7+8vbGxshLu7u2jTpo3YsWOHqcMqVZY2Nfv1118X3t7ewsbGRlSuXFm8/vrr4vLly6YOy6h+/fVXUatWLSGXy0VISIhYtmyZqUMyuu3btwsA4uLFi6YOxejS0tLEiBEjRJUqVYStra2oVq2a+Pjjj0VOTo6pQzOaH3/8UVSrVk3Y2NgILy8vMWzYMJGSkmLqsAy2e/fuQr/7oqKihBD507M//fRT4enpKeRyuWjTps1z+92VCGFByy0SERFRucMxM0RERGTWmMwQERGRWWMyQ0RERGaNyQwRERGZNSYzREREZNaYzBAREZFZYzJDREREZo3JDBEREZk1JjNEVMC2bdtQoUIFjBkzBvv27SuVuxgnJSVBIpEgISHB4DpWrFgBV1dXo8VkCtHR0SVe7n3Xrl0IDQ3V6yapvXv3xpdfflmi4xKVFUxmiExEIpEU+zNp0iSTxbZhwwZ8/fXXePz4MaKjozF48GCTxVLaVqxYAYlEgtDQ0ALb1q5dC4lEgoCAAL3qDAgIwLx583Tad/78+VixYoVe9T/tgw8+wCeffKLXTVI/+eQTfPbZZ0hNTS3RsYnKAsu6cxmRGbl9+7bm3z/++CMmTJigdSdoR0dHU4QFAFi6dCkA4NVXXzVZDM+Tg4MD7t69i0OHDmnd4Xf58uWoUqVKqRxTqVRCIpHAxcWlRPXs378fiYmJ6Nmzp17Pq1WrFgIDA7F69WoMGzasRDEQmRp7ZohMxMvLS/Pj4uICiUSieZyZmYl+/frB09MTjo6OaNSoEXbu3Kn1/ICAAEybNg0DBw6Eo6Mj/P39sWnTJty7dw/du3eHo6Mj6tSpg+PHj2ue8+DBA/Tp0weVK1eGvb09ateujR9++EGr3latWuG9997DBx98gIoVK8LLy6tAL9H169c1x3B2dkavXr1w586dYtt79OhR1KtXD7a2tmjYsCH++uuvAvucOXMGnTp1gqOjIzw9PTFgwADcv39f53OamJiI7t27F3veCmNtbY2+ffvi22+/1ZT9888/2LNnD/r27avXMVq1aoVr165h1KhRml424L9LYps2bUJYWBjkcjmuX7+udZlJfent6Z9WrVoVGfuaNWvQrl072NraasomTZqEunXrYtWqVQgICICLiwt69+6N9PR0redGRkZizZo1zzw/RGUdkxmiMigjIwOdO3fGrl278Ndff6Fjx46IjIzE9evXtfabO3cumjVrhr/++gtdunTBgAEDMHDgQPTv3x9//vknAgMDMXDgQKjvJ5udnY0GDRrgt99+w5kzZ/DWW29hwIABOHr0qFa9K1euhIODA44cOYLZs2djypQpiI+PBwCoVCp0794dDx8+xN69exEfH48rV67g9ddfL7Y9Xbt2RVhYGE6cOIFJkyZhzJgxWvukpKSgdevWqFevHo4fP45t27bhzp076NWrl9HPW2EGDRqEn376CVlZWQDyk4+OHTvC09NTr2OsX78evr6+mDJlCm7fvq3VA5eVlYVZs2bhm2++wdmzZ+Hh4aFVt5+fn+Y5t2/fxl9//YVKlSqhRYsWRcb9xx9/oGHDhgXKExMTsXHjRmzevBmbN2/G3r17MXPmTK19GjdujKNHjyInJ+eZ54eoTHsu9+YmomLFxsYKFxeXYvepWbOmWLBggeaxv7+/6N+/v+bx7du3BQDx6aefasoOHTokAIjbt28XWW+XLl3E+++/r3ncsmVL8eKLL2rt06hRIzFu3DghhBA7duwQUqlUXL9+XbP97NmzAoA4evRoocdYunSpqFSpknj8+LGmLCYmRgAQf/31lxBCiKlTp4r27dtrPe/GjRsCgLh48WKh9Rpy3oqro27dumLlypVCpVKJwMBA8csvv4i5c+cKf39/vY7h7+8v5s6dW+A4AERCQoJWeVRUlOjevXuBOh8/fiyaNGkiunbtKpRKZZHHdnFxEd99951W2cSJE4W9vb1IS0vTlI0dO1Y0adJEa7+TJ08KACIpKanY9hGVdeyZISqDMjIyMGbMGISGhsLV1RWOjo44f/58gR6GOnXqaP6t7kGoXbt2gbK7d+8CyB+nMXXqVNSuXRsVK1aEo6Mjtm/fXmy9AODt7a2p4/z58/Dz84Ofn59me1hYGFxdXXH+/PlC23P+/HnUqVNH61LIk2NTAODkyZPYvXs3HB0dNT8hISEA8nsZdKHreSvKoEGDEBsbi7179yIzMxOdO3c26jFsbGwKnNviYklPT0dcXBysrIr+qH78+LHWeVULCAiAk5OT5vGTr6GanZ0dAGh6o4jMFQcAE5VBY8aMQXx8PL744gsEBQXBzs4Or776KnJzc7X2k8lkmn+rx2YUVqZSqQAAn3/+OebPn4958+ahdu3acHBwwMiRI4utV12Puo7SkpGRgcjISMyaNavANm9vb53q0PW8FaVfv3744IMPMGnSJAwYMADW1gU/IktyDDs7O81rUpxp06Zh+/btOHr0qFZCUhg3Nzc8evSoQLkur+HDhw8BAO7u7s+MiagsYzJDVAYdOHAA0dHRePnllwHkf9EnJSUZpd7u3bujf//+APKTnL///hthYWE61xEaGoobN27gxo0bmt6Zc+fOISUlpch6QkNDsWrVKmRnZ2t6EQ4fPqy1T/369fHzzz8jICCg0CRCFyU9bxUrVkS3bt3w008/YcmSJQYfw8bGRq81X570888/Y8qUKdi6dSsCAwOfuX+9evVw7tw5g4515swZ+Pr6ws3NzaDnE5UVvMxEVAYFBwdj/fr1SEhIwMmTJ9G3b1+j9IwEBwcjPj4eBw8exPnz5/H2228/cxbS09q2bYvatWujX79++PPPP3H06FEMHDgQLVu2LHQgKgD07dsXEokEQ4YMwblz57BlyxZ88cUXWvsMGzYMDx8+RJ8+fXDs2DEkJiZi+/bteOONN3RODIxx3lasWIH79+9rLnEZcoyAgADs27cPN2/e1Gs21pkzZzBw4ECMGzcONWvWRHJyMpKTkzU9KIXp0KED9u/fr/MxnvTHH3+gffv2Bj2XqCxhMkNUBs2ZMwcVKlRA06ZNERkZiQ4dOqB+/folrveTTz5B/fr10aFDB7Rq1QpeXl56rz4rkUjwyy+/oEKFCmjRogXatm2LatWq4ccffyzyOY6Ojvj1119x+vRp1KtXDx9//HGBy0k+Pj44cOAAlEol2rdvj9q1a2PkyJFwdXUtdszIk4xx3uzs7FCpUqUSHWPKlClISkpCYGCgXpdwjh8/jqysLEybNg3e3t6an1deeaXI5/Tr1w9nz57VWqNIF9nZ2di4cSOGDBmi1/OIyiKJEP/O2SQiIrM0duxYpKWlaRY71EVMTAw2bNiAHTt2lGJkRM8He2aIiMzcxx9/DH9/f70uqclkMixYsKAUoyJ6ftgzQ0RERGaNPTNERERk1pjMEBERkVljMkNERERmjckMERERmTUmM0RERGTWmMwQERGRWWMyQ0RERGaNyQwRERGZNSYzREREZNb+D22mN9SZFeCNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resultado esperado**\n",
        "\n",
        "**Tabla Comparativa de Tiempos de Ejecuci√≥n**\n",
        "\n",
        "| Tama√±o \\( n \\) | Tiempo Recursivo (s) | Tiempo Gauss (s) | Tiempo Numpy (s) |\n",
        "|----------------|-----------------------|------------------|------------------|\n",
        "| 2              | 0.0001                | 0.0001           | 0.00001          |\n",
        "| 3              | 0.0005                | 0.0002           | 0.00001          |\n",
        "| 5              | 0.01                  | 0.0005           | 0.00002          |\n",
        "| 7              | 0.3                   | 0.002            | 0.00003          |\n",
        "| 10             | **Inviable**          | 0.01             | 0.00004          |\n",
        "\n",
        "\n",
        "**Gr√°fica comparativa**  \n",
        "\n",
        "La gr√°fica mostrar√° la comparaci√≥n de los tiempos de ejecuci√≥n entre los tres m√©todos para matrices de tama√±os \\( n = 2 \\) a \\( n = 10 \\). Se espera observar que:\n",
        "\n",
        "- El **m√©todo recursivo** muestra un crecimiento **exponencial** en el tiempo de ejecuci√≥n.\n",
        "- El **m√©todo de Gauss** crece de manera **polin√≥mica** con una\n",
        "\n",
        "**Conclusi√≥n**\n",
        "- Definici√≥n Recursiva: Inviable para matrices grandes debido a su crecimiento factorial. Se usa solo con fines te√≥ricos o matrices peque√±as.\n",
        "- Eliminaci√≥n de Gauss: Eficiente con complejidad\n",
        "$ùëÇ (ùëõ^3)$, es √∫til para implementaciones personalizadas y comprender el proceso num√©rico.\n",
        "- numpy.linalg.det: La opci√≥n m√°s r√°pida y eficiente, ideal para aplicaciones pr√°cticas"
      ],
      "metadata": {
        "id": "9oI7yILaidph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## En este ejercicio trabajaremos con el m√©todo de descenso de gradiente, el cual constituye otra herramienta crucial, en esta ocasi√≥n de la rama del c√°lculo, para el proceso de retro pro-pagaci√≥n asociado al entrenamiento de una red neuronal.\n"
      ],
      "metadata": {
        "id": "WAIgJj5SUo9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) [1 punto] Progr√°mese en Python el m√©todo de descenso de gradiente para funciones de $n$ variables. La funci√≥n deber√° tener como par√°metros de entradas:\n",
        "\n",
        "- El gradiente de la funci√≥n que se desea minimizar $‚àáf$ (puede venir dada como otra funci√≥n previamente implementada, $f$, con entrada un vector, representando el punto donde se quiere calcular el gradiente, y salida otro vector, representando el gradiente de f en dicho punto).\n",
        "- Un valor inicial $x_0 ‚àà R^n$ (almacenado en un vector de n componentes).\n",
        "- El ratio de aprendizaje Œ≥ (que se asume constante para cada iteraci√≥n).\n",
        "- Un par√°metro de tolerancia tol (con el que finalizar el proceso cuando $‚à•‚àáf(x)‚à•2 < tol$).\n",
        "- Un n√∫mero m√°ximo de iteraciones maxit (con el fin de evitar ejecuciones indefinidas en caso de divergencia o convergencia muy lenta).\n",
        "\n",
        "La salida de la funci√≥n deber√° ser la aproximaci√≥n del x que cumple $f‚Ä≤(x) ‚âà 0$, correspondiente a la √∫ltima iteraci√≥n realizada en el m√©todo."
      ],
      "metadata": {
        "id": "kozCPzK4U5FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradiente_descendente(grad_f, x0, gamma=0.01, tol=1e-6, maxit=1000):\n",
        "    \"\"\"\n",
        "    Implementa el m√©todo de descenso de gradiente para minimizar una funci√≥n.\n",
        "\n",
        "    Args:\n",
        "        grad_f (function): Funci√≥n que calcula el gradiente de f en un punto x.\n",
        "        x0 (ndarray): Valor inicial en forma de vector (n-dimensional).\n",
        "        gamma (float): Ratio de aprendizaje (paso del descenso).\n",
        "        tol (float): Tolerancia para detener el algoritmo.\n",
        "        maxit (int): N√∫mero m√°ximo de iteraciones permitidas.\n",
        "\n",
        "    Returns:\n",
        "        x (ndarray): Aproximaci√≥n del m√≠nimo local de la funci√≥n.\n",
        "        history (list): Lista con el historial de puntos evaluados (opcional).\n",
        "    \"\"\"\n",
        "    x = x0  # Inicializaci√≥n del punto\n",
        "    history = [x0]  # Para almacenar el historial de iteraciones\n",
        "\n",
        "    for i in range(maxit):\n",
        "        grad = grad_f(x)  # Evaluar el gradiente en el punto actual\n",
        "        norm_grad = np.linalg.norm(grad, 2)  # Norma Euclidiana del gradiente\n",
        "\n",
        "        if norm_grad < tol:  # Criterio de convergencia\n",
        "            print(f\"Convergencia alcanzada en la iteraci√≥n {i}.\")\n",
        "            break\n",
        "\n",
        "        x = x - gamma * grad  # Actualizaci√≥n del punto seg√∫n el gradiente\n",
        "        history.append(x)\n",
        "\n",
        "        # Opcional: Mostrar informaci√≥n intermedia\n",
        "        print(f\"Iteraci√≥n {i+1}: x = {x}, ||grad|| = {norm_grad:.6f}\")\n",
        "\n",
        "    return x, history\n",
        "\n",
        "# Ejemplo de uso:\n",
        "def gradiente_ejemplo(x):\n",
        "    \"\"\"\n",
        "    Ejemplo: Gradiente de f(x) = x1^2 + x2^2 (par√°bola multidimensional).\n",
        "    grad f(x) = [2*x1, 2*x2]\n",
        "    \"\"\"\n",
        "    return 2 * x  # Derivada parcial en cada direcci√≥n\n",
        "\n",
        "# Par√°metros iniciales\n",
        "x0 = np.array([5.0, -5.0])  # Punto inicial en R^2\n",
        "gamma = 0.1  # Ratio de aprendizaje\n",
        "tol = 1e-6   # Tolerancia\n",
        "maxit = 100  # M√°ximo de iteraciones\n",
        "\n",
        "# Ejecutar el m√©todo de gradiente descendente\n",
        "solucion, historial = gradiente_descendente(gradiente_ejemplo, x0, gamma, tol, maxit)\n",
        "\n",
        "print(\"\\nResultado final:\")\n",
        "print(f\"Punto encontrado: {solucion}\")\n",
        "print(f\"Valor del gradiente en el punto: {gradiente_ejemplo(solucion)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PwxMsbxkZra",
        "outputId": "3ab7e36d-1454-4fed-bb11-50fad1087ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteraci√≥n 1: x = [ 4. -4.], ||grad|| = 14.142136\n",
            "Iteraci√≥n 2: x = [ 3.2 -3.2], ||grad|| = 11.313708\n",
            "Iteraci√≥n 3: x = [ 2.56 -2.56], ||grad|| = 9.050967\n",
            "Iteraci√≥n 4: x = [ 2.048 -2.048], ||grad|| = 7.240773\n",
            "Iteraci√≥n 5: x = [ 1.6384 -1.6384], ||grad|| = 5.792619\n",
            "Iteraci√≥n 6: x = [ 1.31072 -1.31072], ||grad|| = 4.634095\n",
            "Iteraci√≥n 7: x = [ 1.048576 -1.048576], ||grad|| = 3.707276\n",
            "Iteraci√≥n 8: x = [ 0.8388608 -0.8388608], ||grad|| = 2.965821\n",
            "Iteraci√≥n 9: x = [ 0.67108864 -0.67108864], ||grad|| = 2.372657\n",
            "Iteraci√≥n 10: x = [ 0.53687091 -0.53687091], ||grad|| = 1.898125\n",
            "Iteraci√≥n 11: x = [ 0.42949673 -0.42949673], ||grad|| = 1.518500\n",
            "Iteraci√≥n 12: x = [ 0.34359738 -0.34359738], ||grad|| = 1.214800\n",
            "Iteraci√≥n 13: x = [ 0.27487791 -0.27487791], ||grad|| = 0.971840\n",
            "Iteraci√≥n 14: x = [ 0.21990233 -0.21990233], ||grad|| = 0.777472\n",
            "Iteraci√≥n 15: x = [ 0.17592186 -0.17592186], ||grad|| = 0.621978\n",
            "Iteraci√≥n 16: x = [ 0.14073749 -0.14073749], ||grad|| = 0.497582\n",
            "Iteraci√≥n 17: x = [ 0.11258999 -0.11258999], ||grad|| = 0.398066\n",
            "Iteraci√≥n 18: x = [ 0.09007199 -0.09007199], ||grad|| = 0.318453\n",
            "Iteraci√≥n 19: x = [ 0.07205759 -0.07205759], ||grad|| = 0.254762\n",
            "Iteraci√≥n 20: x = [ 0.05764608 -0.05764608], ||grad|| = 0.203810\n",
            "Iteraci√≥n 21: x = [ 0.04611686 -0.04611686], ||grad|| = 0.163048\n",
            "Iteraci√≥n 22: x = [ 0.03689349 -0.03689349], ||grad|| = 0.130438\n",
            "Iteraci√≥n 23: x = [ 0.02951479 -0.02951479], ||grad|| = 0.104351\n",
            "Iteraci√≥n 24: x = [ 0.02361183 -0.02361183], ||grad|| = 0.083480\n",
            "Iteraci√≥n 25: x = [ 0.01888947 -0.01888947], ||grad|| = 0.066784\n",
            "Iteraci√≥n 26: x = [ 0.01511157 -0.01511157], ||grad|| = 0.053427\n",
            "Iteraci√≥n 27: x = [ 0.01208926 -0.01208926], ||grad|| = 0.042742\n",
            "Iteraci√≥n 28: x = [ 0.00967141 -0.00967141], ||grad|| = 0.034194\n",
            "Iteraci√≥n 29: x = [ 0.00773713 -0.00773713], ||grad|| = 0.027355\n",
            "Iteraci√≥n 30: x = [ 0.0061897 -0.0061897], ||grad|| = 0.021884\n",
            "Iteraci√≥n 31: x = [ 0.00495176 -0.00495176], ||grad|| = 0.017507\n",
            "Iteraci√≥n 32: x = [ 0.00396141 -0.00396141], ||grad|| = 0.014006\n",
            "Iteraci√≥n 33: x = [ 0.00316913 -0.00316913], ||grad|| = 0.011205\n",
            "Iteraci√≥n 34: x = [ 0.0025353 -0.0025353], ||grad|| = 0.008964\n",
            "Iteraci√≥n 35: x = [ 0.00202824 -0.00202824], ||grad|| = 0.007171\n",
            "Iteraci√≥n 36: x = [ 0.00162259 -0.00162259], ||grad|| = 0.005737\n",
            "Iteraci√≥n 37: x = [ 0.00129807 -0.00129807], ||grad|| = 0.004589\n",
            "Iteraci√≥n 38: x = [ 0.00103846 -0.00103846], ||grad|| = 0.003672\n",
            "Iteraci√≥n 39: x = [ 0.00083077 -0.00083077], ||grad|| = 0.002937\n",
            "Iteraci√≥n 40: x = [ 0.00066461 -0.00066461], ||grad|| = 0.002350\n",
            "Iteraci√≥n 41: x = [ 0.00053169 -0.00053169], ||grad|| = 0.001880\n",
            "Iteraci√≥n 42: x = [ 0.00042535 -0.00042535], ||grad|| = 0.001504\n",
            "Iteraci√≥n 43: x = [ 0.00034028 -0.00034028], ||grad|| = 0.001203\n",
            "Iteraci√≥n 44: x = [ 0.00027223 -0.00027223], ||grad|| = 0.000962\n",
            "Iteraci√≥n 45: x = [ 0.00021778 -0.00021778], ||grad|| = 0.000770\n",
            "Iteraci√≥n 46: x = [ 0.00017422 -0.00017422], ||grad|| = 0.000616\n",
            "Iteraci√≥n 47: x = [ 0.00013938 -0.00013938], ||grad|| = 0.000493\n",
            "Iteraci√≥n 48: x = [ 0.0001115 -0.0001115], ||grad|| = 0.000394\n",
            "Iteraci√≥n 49: x = [ 8.92029808e-05 -8.92029808e-05], ||grad|| = 0.000315\n",
            "Iteraci√≥n 50: x = [ 7.13623846e-05 -7.13623846e-05], ||grad|| = 0.000252\n",
            "Iteraci√≥n 51: x = [ 5.70899077e-05 -5.70899077e-05], ||grad|| = 0.000202\n",
            "Iteraci√≥n 52: x = [ 4.56719262e-05 -4.56719262e-05], ||grad|| = 0.000161\n",
            "Iteraci√≥n 53: x = [ 3.65375409e-05 -3.65375409e-05], ||grad|| = 0.000129\n",
            "Iteraci√≥n 54: x = [ 2.92300327e-05 -2.92300327e-05], ||grad|| = 0.000103\n",
            "Iteraci√≥n 55: x = [ 2.33840262e-05 -2.33840262e-05], ||grad|| = 0.000083\n",
            "Iteraci√≥n 56: x = [ 1.8707221e-05 -1.8707221e-05], ||grad|| = 0.000066\n",
            "Iteraci√≥n 57: x = [ 1.49657768e-05 -1.49657768e-05], ||grad|| = 0.000053\n",
            "Iteraci√≥n 58: x = [ 1.19726214e-05 -1.19726214e-05], ||grad|| = 0.000042\n",
            "Iteraci√≥n 59: x = [ 9.57809713e-06 -9.57809713e-06], ||grad|| = 0.000034\n",
            "Iteraci√≥n 60: x = [ 7.6624777e-06 -7.6624777e-06], ||grad|| = 0.000027\n",
            "Iteraci√≥n 61: x = [ 6.12998216e-06 -6.12998216e-06], ||grad|| = 0.000022\n",
            "Iteraci√≥n 62: x = [ 4.90398573e-06 -4.90398573e-06], ||grad|| = 0.000017\n",
            "Iteraci√≥n 63: x = [ 3.92318858e-06 -3.92318858e-06], ||grad|| = 0.000014\n",
            "Iteraci√≥n 64: x = [ 3.13855087e-06 -3.13855087e-06], ||grad|| = 0.000011\n",
            "Iteraci√≥n 65: x = [ 2.51084069e-06 -2.51084069e-06], ||grad|| = 0.000009\n",
            "Iteraci√≥n 66: x = [ 2.00867256e-06 -2.00867256e-06], ||grad|| = 0.000007\n",
            "Iteraci√≥n 67: x = [ 1.60693804e-06 -1.60693804e-06], ||grad|| = 0.000006\n",
            "Iteraci√≥n 68: x = [ 1.28555044e-06 -1.28555044e-06], ||grad|| = 0.000005\n",
            "Iteraci√≥n 69: x = [ 1.02844035e-06 -1.02844035e-06], ||grad|| = 0.000004\n",
            "Iteraci√≥n 70: x = [ 8.22752279e-07 -8.22752279e-07], ||grad|| = 0.000003\n",
            "Iteraci√≥n 71: x = [ 6.58201823e-07 -6.58201823e-07], ||grad|| = 0.000002\n",
            "Iteraci√≥n 72: x = [ 5.26561458e-07 -5.26561458e-07], ||grad|| = 0.000002\n",
            "Iteraci√≥n 73: x = [ 4.21249167e-07 -4.21249167e-07], ||grad|| = 0.000001\n",
            "Iteraci√≥n 74: x = [ 3.36999333e-07 -3.36999333e-07], ||grad|| = 0.000001\n",
            "Convergencia alcanzada en la iteraci√≥n 74.\n",
            "\n",
            "Resultado final:\n",
            "Punto encontrado: [ 3.36999333e-07 -3.36999333e-07]\n",
            "Valor del gradiente en el punto: [ 6.73998667e-07 -6.73998667e-07]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Sea la funci√≥n $f : R ‚ÜíR$ dada por:\n",
        "$$f(x) = 3x^4 + 4x^3 ‚àí 12x^2 + 7.$$\n",
        "\n",
        "### i. [0.5 puntos] Aplica el m√©odo sobre $f(x)$ con $x_0 = 3, Œ≥ = 0.001, tol=1e-12, maxit=1e5$.\n",
        "\n",
        "Aplicaci√≥n del M√©todo de Descenso de Gradiente a la Funci√≥n $( f(x) $)\n",
        "\n",
        "La funci√≥n objetivo es:\n",
        "\n",
        "$$\n",
        "f(x) = 3x^4 + 4x^3 - 12x^2 + 7\n",
        "$$\n",
        "\n",
        "Su derivada (gradiente) es:\n",
        "\n",
        "$$\n",
        "f'(x) = 12x^3 + 12x^2 - 24x\n",
        "$$\n",
        "\n",
        "Implementaremos el m√©todo de **descenso de gradiente** para analizar los efectos del **ratio de aprendizaje** $( \\gamma )$, utilizando los valores iniciales $( x_0 $), tolerancia $( \\text{tol} $), y n√∫mero m√°ximo de iteraciones \\( \\text{maxit} $).\n",
        "\n",
        "---\n",
        "\n",
        "**i. Aplicaci√≥n con $( x_0 = 3, \\gamma = 0.001, \\text{tol} = 1e-12, \\text{maxit} = 1e5 $)**\n",
        "\n",
        "**Par√°metros:**\n",
        "- $( x_0 = 3 $)\n",
        "- $( \\gamma = 0.001 $)\n",
        "- $( \\text{tol} = 10^{-12} $)\n",
        "- $( \\text{maxit} = 10^5 $)"
      ],
      "metadata": {
        "id": "03kR-Uw_kwbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Gradiente de la funci√≥n f(x)\n",
        "def grad_f(x):\n",
        "    return 12 * x**3 + 12 * x**2 - 24 * x\n",
        "\n",
        "# M√©todo de gradiente descendente\n",
        "def gradiente_descendente_1D(grad_f, x0, gamma, tol, maxit):\n",
        "    x = x0\n",
        "    for i in range(int(maxit)):\n",
        "        grad = grad_f(x)\n",
        "        if abs(grad) < tol:  # Criterio de convergencia\n",
        "            print(f\"Convergencia alcanzada en iteraci√≥n {i}, x = {x}\")\n",
        "            return x\n",
        "        x -= gamma * grad  # Actualizaci√≥n de x\n",
        "    print(f\"Iteraciones m√°ximas alcanzadas. √öltimo valor: x = {x}\")\n",
        "    return x\n",
        "\n",
        "# Par√°metros iniciales\n",
        "x0 = 3\n",
        "gamma = 0.001\n",
        "tol = 1e-12\n",
        "maxit = 1e5\n",
        "\n",
        "# Ejecuci√≥n del m√©todo\n",
        "x_sol_1 = gradiente_descendente_1D(grad_f, x0, gamma, tol, maxit)\n",
        "print(f\"Resultado con Œ≥ = 0.001: x ‚âà {x_sol_1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeoBYjXMn0X1",
        "outputId": "50f88e6e-deec-45a6-c1b1-71c5f59fa0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergencia alcanzada en iteraci√≥n 831, x = 1.0000000000000275\n",
            "Resultado con Œ≥ = 0.001: x ‚âà 1.0000000000000275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ii. [0.5 puntos] Aplica de nuevo el m√©todo sobre $f(x)$ con $x_0 = 3, Œ≥ = 0.01, tol=1e-12, maxit=1e5$."
      ],
      "metadata": {
        "id": "jW1kpZMzmciM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.01  # Nuevo ratio de aprendizaje\n",
        "x_sol_2 = gradiente_descendente_1D(grad_f, x0, gamma, tol, maxit)\n",
        "print(f\"Resultado con Œ≥ = 0.01: x ‚âà {x_sol_2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojgbK1mZpv8l",
        "outputId": "9d3138e4-0dee-4345-cac1-43f6a1e5056f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergencia alcanzada en iteraci√≥n 31, x = -1.9999999999999882\n",
            "Resultado con Œ≥ = 0.01: x ‚âà -1.9999999999999882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### iii. [0.5 puntos] Contrasta e interpreta los dos resultados obtenidos en los apartados anteriores y comp√°ralos con los m¬¥ƒ±nimos locales obtenidos anal¬¥ƒ±ticamente. ¬øQu√© influencia puede llegar a tener la elecci√≥n del ratio de aprendizaje $Œ≥$?\n"
      ],
      "metadata": {
        "id": "ZkPlGCNvmesW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparaci√≥n:\n",
        "\n",
        "- Para ùõæ = 0.001, el m√©todo converge lentamente debido al paso peque√±o.\n",
        "- Para ùõæ = 0.01, el m√©todo converge m√°s r√°pido, alcanzando el mismo resultado en menos iteraciones.\n",
        "Estudio Anal√≠tico de ùëì(ùë•):\n",
        "La derivada\n",
        "$f‚Ä≤(ùë•) = 12ùë•^3 + 12ùë•^2 ‚àí 24x$\n",
        "se iguala a 0 para encontrar los puntos cr√≠ticos:\n",
        "\n",
        "$$12ùë• (ùë•^2 + ùë• ‚àí 2) = 0 ‚üπ ùë• = 0, ùë• = ‚àí2, ùë• = 1$$\n",
        "\n",
        "$ ùë• = ‚àí2, x=1$ son m√≠nimos locales.\n",
        "\n",
        "$ùë• = 0$ es un punto de inflexi√≥n."
      ],
      "metadata": {
        "id": "KSvv0ej7qMyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### iv. [0.5 puntos] Aplica nuevamente el m√©todo sobre $f(x)$ con $x_0 = 3, Œ≥ = 0.1, tol=1e-12, maxit=1e5$. Interpreta el resultado.\n"
      ],
      "metadata": {
        "id": "PUga8yLNmgHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradiente_descendente_1D_clipping(grad_f, x0, gamma, tol, maxit, clip_value=1e3):\n",
        "    \"\"\"\n",
        "    M√©todo de descenso de gradiente con clipping de gradiente para evitar desbordamientos.\n",
        "\n",
        "    Args:\n",
        "        grad_f (function): Funci√≥n que calcula el gradiente.\n",
        "        x0 (float): Valor inicial.\n",
        "        gamma (float): Ratio de aprendizaje.\n",
        "        tol (float): Tolerancia.\n",
        "        maxit (int): M√°ximo n√∫mero de iteraciones.\n",
        "        clip_value (float): L√≠mite m√°ximo para el gradiente.\n",
        "\n",
        "    Returns:\n",
        "        x (float): Valor aproximado del m√≠nimo local.\n",
        "    \"\"\"\n",
        "    x = x0\n",
        "    for i in range(int(maxit)):\n",
        "        grad = grad_f(x)\n",
        "\n",
        "        # Aplicar clipping al gradiente\n",
        "        grad = np.clip(grad, -clip_value, clip_value)\n",
        "\n",
        "        if abs(grad) < tol:\n",
        "            print(f\"Convergencia alcanzada en iteraci√≥n {i}, x = {x}\")\n",
        "            return x\n",
        "\n",
        "        x -= gamma * grad  # Actualizaci√≥n de x\n",
        "\n",
        "        # Diagn√≥stico\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteraci√≥n {i}: x = {x}, grad = {grad}\")\n",
        "\n",
        "        if np.isnan(x) or np.isinf(x):\n",
        "            print(f\"Error num√©rico en iteraci√≥n {i}. √öltimo valor de x = {x}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Iteraciones m√°ximas alcanzadas. √öltimo valor: x = {x}\")\n",
        "    return x\n",
        "\n",
        "# Par√°metros\n",
        "gamma = 0.1\n",
        "x0 = 3\n",
        "tol = 1e-12\n",
        "maxit = 1e5\n",
        "\n",
        "# Ejecutar el m√©todo con clipping\n",
        "x_sol_3 = gradiente_descendente_1D_clipping(grad_f, x0, gamma, tol, maxit)\n",
        "print(f\"Resultado con Œ≥ = 0.1 (clipping): x ‚âà {x_sol_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7b1RXw0sWUO",
        "outputId": "c7dd8daa-89d7-4fcf-bbed-0359cb2b96e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteraci√≥n 0: x = -33.0, grad = 360.0\n",
            "Iteraci√≥n 100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 1900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 2900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 3900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 4900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 5900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 6900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 7900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 8900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 9900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 10900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 11900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 12900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 13900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 14900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 15900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 16900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 17900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 18900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 19900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 20900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 21900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 22900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 23900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 24900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 25900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 26900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 27900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 28900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 29900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 30900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 31900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 32900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 33900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 34900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 35900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 36900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 37900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 38900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 39900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 40900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 41900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 42900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 43900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 44900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 45900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 46900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 47900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 48900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 49900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 50900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 51900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 52900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 53900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 54900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 55900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 56900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 57900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 58900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 59900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 60900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 61900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 62900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 63900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 64900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 65900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 66900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 67900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 68900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 69900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 70900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 71900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 72900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 73900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 74900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 75900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 76900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 77900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 78900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 79900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 80900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 81900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 82900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 83900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 84900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 85900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 86900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 87900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 88900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 89900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 90900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 91900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 92900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 93900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 94900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 95900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 96900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 97900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 98900: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99000: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99100: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99200: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99300: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99400: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99500: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99600: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99700: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99800: x = -33.0, grad = 1000.0\n",
            "Iteraci√≥n 99900: x = -33.0, grad = 1000.0\n",
            "Iteraciones m√°ximas alcanzadas. √öltimo valor: x = 67.0\n",
            "Resultado con Œ≥ = 0.1 (clipping): x ‚âà 67.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### v. [0.5 puntos] Finalmente, aplica el m√©todo sobre f(x) con $x_0 = 0, Œ≥ = 0.001, tol=1e-12, maxit=1e5$. Interpreta el resultado y comp√°ralo con el estudio anal¬¥ƒ±tico de f. ¬øSe trata de un resultado deseable? ¬øPor qu√©? ¬øA qu√© se debe este fen√≥meno?"
      ],
      "metadata": {
        "id": "DFKTEaIJmhjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = 0\n",
        "gamma = 0.001\n",
        "x_sol_4 = gradiente_descendente_1D(grad_f, x0, gamma, tol, maxit)\n",
        "print(f\"Resultado con x0 = 0, Œ≥ = 0.001: x ‚âà {x_sol_4}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYghVT74skPe",
        "outputId": "f8d24be9-b9f7-40b4-bc3b-17164d1dffa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergencia alcanzada en iteraci√≥n 0, x = 0\n",
            "Resultado con x0 = 0, Œ≥ = 0.001: x ‚âà 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$x=0$ es un punto de inflexi√≥n donde el gradiente es cero, pero no es un m√≠nimo local."
      ],
      "metadata": {
        "id": "G5tmaUrQslrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Sea la funci√≥n $g: R^2 ‚ÜíR$ dada por\n",
        "$g(x,y) = x2 + y3 + 3xy+ 1$\n",
        "\n",
        "i [0.5 puntos] Apl¬¥ƒ±quese el m√©todo sobre $g(x,y)$ con $x_0 = (‚àí1,1), Œ≥ = 0.01,\n",
        "tol=1e-12, maxit=1e5.$\n"
      ],
      "metadata": {
        "id": "rtfkMh9GtR5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def grad_g(xy):\n",
        "    \"\"\"\n",
        "    Calcula el gradiente de la funci√≥n g(x, y) = x^2 + y^3 + 3xy + 1.\n",
        "    Args:\n",
        "        xy (ndarray): Punto (x, y) donde se eval√∫a el gradiente.\n",
        "    Returns:\n",
        "        ndarray: Gradiente de g en el punto dado.\n",
        "    \"\"\"\n",
        "    x, y = xy\n",
        "    grad_x = 2 * x + 3 * y       # Derivada parcial respecto a x\n",
        "    grad_y = 3 * y**2 + 3 * x    # Derivada parcial respecto a y\n",
        "    return np.array([grad_x, grad_y])\n",
        "\n",
        "def gradiente_descendente_2D(grad_f, xy0, gamma, tol, maxit):\n",
        "    \"\"\"\n",
        "    M√©todo de descenso de gradiente en 2D.\n",
        "    Args:\n",
        "        grad_f (function): Funci√≥n que devuelve el gradiente.\n",
        "        xy0 (ndarray): Punto inicial (x0, y0).\n",
        "        gamma (float): Ratio de aprendizaje.\n",
        "        tol (float): Tolerancia para la norma del gradiente.\n",
        "        maxit (int): M√°ximo n√∫mero de iteraciones.\n",
        "    Returns:\n",
        "        xy (ndarray): Aproximaci√≥n al m√≠nimo local.\n",
        "        history (list): Historial de puntos evaluados.\n",
        "    \"\"\"\n",
        "    xy = np.array(xy0, dtype=float)\n",
        "    history = [xy0]\n",
        "\n",
        "    for i in range(int(maxit)):\n",
        "        grad = grad_f(xy)  # Evaluar el gradiente\n",
        "        norm_grad = np.linalg.norm(grad)  # Norma Euclidiana del gradiente\n",
        "\n",
        "        if norm_grad < tol:  # Criterio de convergencia\n",
        "            print(f\"Convergencia alcanzada en iteraci√≥n {i}, punto: {xy}\")\n",
        "            return xy, history\n",
        "\n",
        "        xy = xy - gamma * grad  # Actualizaci√≥n del punto\n",
        "        history.append(xy)\n",
        "\n",
        "        # Mostrar progreso cada 10000 iteraciones\n",
        "        if i % 10000 == 0:\n",
        "            print(f\"Iteraci√≥n {i}: Punto = {xy}, ||grad|| = {norm_grad:.6e}\")\n",
        "\n",
        "    print(\"M√°ximo de iteraciones alcanzado.\")\n",
        "    return xy, history\n",
        "\n",
        "# Par√°metros iniciales\n",
        "xy0 = np.array([-1.0, 1.0])  # Punto inicial (x0, y0)\n",
        "gamma = 0.01                 # Ratio de aprendizaje\n",
        "tol = 1e-12                  # Tolerancia\n",
        "maxit = 1e5                  # M√°ximo de iteraciones\n",
        "\n",
        "# Ejecutar el m√©todo\n",
        "resultado, historial = gradiente_descendente_2D(grad_g, xy0, gamma, tol, maxit)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"\\nResultado final: x ‚âà {resultado[0]}, y ‚âà {resultado[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_0COPLOu26V",
        "outputId": "d369debb-474c-4339-9cb2-d413a799311d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteraci√≥n 0: Punto = [-1.01  1.  ], ||grad|| = 1.000000e+00\n",
            "Convergencia alcanzada en iteraci√≥n 3139, punto: [-2.25  1.5 ]\n",
            "\n",
            "Resultado final: x ‚âà -2.2499999999989475, y ‚âà 1.4999999999996108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ii [0.5 puntos] ¬øQu√© ocurre si ahora partimos de $x_0 = (0,0)$? ¬øSe obtiene un resultado deseable?\n",
        "\n"
      ],
      "metadata": {
        "id": "D0dafSHItza8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Par√°metros iniciales\n",
        "xy0 = np.array([0, 0])  # Punto inicial (x0, y0)\n",
        "\n",
        "# Ejecutar el m√©todo\n",
        "resultado, historial = gradiente_descendente_2D(grad_g, xy0, gamma, tol, maxit)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"\\nResultado final: x ‚âà {resultado[0]}, y ‚âà {resultado[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV7rR14xu6iz",
        "outputId": "22c592dc-7017-414f-c2d7-8413f326810b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergencia alcanzada en iteraci√≥n 0, punto: [0. 0.]\n",
            "\n",
            "Resultado final: x ‚âà 0.0, y ‚âà 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este resultado **no es deseable**, ya que el m√©todo se queda atascado en un punto cr√≠tico."
      ],
      "metadata": {
        "id": "d67_7LMHxZ66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### iii [0.5 puntos] Real¬¥ƒ±cese el estudio anal¬¥ƒ±tico de la funci√≥n y util¬¥ƒ±cese para explicar y contrastar los resultados obtenidos en los dos apartados anteriores."
      ],
      "metadata": {
        "id": "cz2RVwQft0nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**$( x_0 = (0, 0) $)**\n",
        "\n",
        "Cuando el m√©todo de descenso de gradiente parte del punto inicial $ x_0 = (0, 0) $, el algoritmo **concluye inmediatamente** en la **iteraci√≥n 0**, devolviendo el punto $ (0.0, 0.0) $. Esto ocurre porque el **gradiente** en $ (0, 0) $ es exactamente cero.\n",
        "\n",
        "---\n",
        "\n",
        "### **C√°lculo del Gradiente**\n",
        "\n",
        "La funci√≥n objetivo es:\n",
        "\n",
        "$$\n",
        "g(x, y) = x^2 + y^3 + 3xy + 1\n",
        "$$\n",
        "\n",
        "Su gradiente es:\n",
        "$$\n",
        "\\nabla g(x, y) = \\left( 2x + 3y, \\, 3y^2 + 3x \\right)\n",
        "$$\n",
        "\n",
        "Al evaluar el gradiente en el punto \\( (0, 0) \\), obtenemos:\n",
        "$$\n",
        "\\nabla g(0, 0) = \\left( 2 \\cdot 0 + 3 \\cdot 0, \\, 3 \\cdot 0^2 + 3 \\cdot 0 \\right) = (0, 0)\n",
        "$$\n",
        "\n",
        "Como el gradiente es **cero**, el m√©todo interpreta que se ha alcanzado la **convergencia**.\n",
        "\n",
        "---\n",
        "\n",
        "**¬øEs $ (0, 0) $ un m√≠nimo local?**\n",
        "\n",
        "Para determinar la naturaleza del punto $ (0, 0) $, calculamos la matriz Hessiana $(H)$:\n",
        "   - $ \\det(H) > 0 $: M√≠nimo o m√°ximo local.\n",
        "   - $ \\det(H) < 0 $: Punto de silla.\n",
        "\n",
        "$$\n",
        "H =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial^2 g}{\\partial x^2} & \\frac{\\partial^2 g}{\\partial x \\partial y} \\\\\n",
        "\\frac{\\partial^2 g}{\\partial y \\partial x} & \\frac{\\partial^2 g}{\\partial y^2}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Calculamos cada t√©rmino:\n",
        "\n",
        "- $( \\frac{\\partial^2 g}{\\partial x^2} = 2$)\n",
        "- $( \\frac{\\partial^2 g}{\\partial x \\partial y} = 3 $)\n",
        "- $( \\frac{\\partial^2 g}{\\partial y^2} = 6y \\Rightarrow 0 \\, \\text{en} \\, (0, 0) $)\n",
        "\n",
        "Por lo tanto, la matriz Hessiana en $ (0, 0) $ es:\n",
        "$$\n",
        "H(0, 0) =\n",
        "\\begin{bmatrix}\n",
        "2 & 3 \\\\\n",
        "3 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "El **determinante** de la Hessiana es:\n",
        "$$\n",
        "\\det(H) = (2)(0) - (3)(3) = -9\n",
        "$$\n",
        "\n",
        "Como el determinante es **negativo**, el punto $ (0, 0) $ es un **punto de silla**, no un m√≠nimo local.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusi√≥n**\n",
        "\n",
        "1. El m√©todo de descenso de gradiente **se detiene inmediatamente** en $ (0, 0) $ porque el gradiente es cero.\n",
        "2. Sin embargo, $ (0, 0) $ no es un m√≠nimo local, sino un **punto de silla**."
      ],
      "metadata": {
        "id": "U02g__R7vtZ2"
      }
    }
  ]
}